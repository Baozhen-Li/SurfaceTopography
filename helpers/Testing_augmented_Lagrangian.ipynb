{
 "metadata": {
  "name": "",
  "signature": "sha256:265c05a8915e00bd1baa8ee2676d096b98f40feb97be5dfcc08293d31960be8f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "source": [
      "Testing the Augmented Lagrangian of PyPyContact"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "The implementation of the augmented Lagrangian in PyPyContact.Tools follows closely the description of the `LANCELOT` algorithm described in Bierlaire (2006)"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "The function `augmented_lagrangian` has the form of custom minimizer for [scipy.optimize.minimize](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.minimize.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import os\n",
      "import numpy as np\n",
      "\n",
      "import scipy.optimize\n",
      "import scipy\n",
      "sys.path.append(os.path.join(os.getcwd(), \"../PyPyContact/Tools/\"))\n",
      "#from AugmentedLagrangian import augmented_lagrangian"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "Book example"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "Example 20.5: Minimise the fuction $f(x)$\n",
      "$$\\min_{x\\in\\mathbb{R}^2} 2(x_1^2+x_2^2 -1)-x_1$$\n",
      "under the constraint\n",
      "$$ x_1^2 + x_2^2 = 1$$"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "ugly workaround to get a fresh AugmentedLagrangian without module loads"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fname = \"../PyPyContact/Tools/AugmentedLagrangian.py\"\n",
      "#with open(fname) as filehandle:\n",
      "#    content = ''.join((line for line in filehandle))\n",
      "#exec(content)\n",
      "#from PyPyContact.Tools.Optimisation import augmented_lagrangian\n",
      "from copy import deepcopy\n",
      "from PyPyContact.Tools.Optimisation import ReachedTolerance, ReachedMaxiter, FailedIterate\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# implemented as a custom minimizer for scipy\n",
      "def augmented_lagrangian(fun, x0, args=(), constraints=None, tol=1e-5,\n",
      "                         update_tol0=.1, multiplier0=None, penalty0=10, alpha=0.1,\n",
      "                         beta=0.9, tau=10, min_method='L-BFGS-B', callback=None,\n",
      "                         bounds=None, jac=None, hess=None, constraints_jac=None,\n",
      "                         constraints_hess=None,\n",
      "                         hessp=None, store_iterates=None, **options):\n",
      "    \"\"\"\n",
      "    Custom minimizer that implements the LANCELOT (Conn et al., 1992) augmented\n",
      "    Lagrangian minimizer. For documentation, see Bierlaire (2006)\n",
      "\n",
      "\n",
      "    Bierlaire (2006):\n",
      "    Introduction \u00e0 l'optimization diff\u00e9rentiable, Michel Bierlaire, Presses\n",
      "    polytechniques et universitaires romandes, Lausanne 2006,\n",
      "    ISBN:2-88074-669-8\n",
      "\n",
      "    Keyword Arguments:\n",
      "    fun         -- objective function to minimize. R\u207f\u2192R\n",
      "    x0          -- initial guess for solution, x0 in R\u207f\n",
      "    args        -- (default empty) additional arguments that need to be fed to fun\n",
      "    constraints -- (default None) not optional. An exception will be raised if\n",
      "                   this is not specified. A callable that is called as\n",
      "                   constraints(x, args=args) and returns an ndarray of same\n",
      "                   length as multiplier0. R\u207f\u2192R\u1d50\n",
      "    tol         -- (default None) Convergence tolerance. Is used for both the\n",
      "                   subjacent minimizer as well as for the outer (augmented\n",
      "                   Lagrangian) loop.\n",
      "    update_tol0 -- (default .1) This value is used to decide whether the\n",
      "                   minimum x_k is \"sufficiently\" admissible: if\n",
      "                   ||constraints(x_k, args=args)|| < current update_tol, then\n",
      "                   the multipliers are updated, else the penalty is increased.\n",
      "    multiplier0 -- (default None) Initial guess for the Lagrange multipliers. in R\u1d50 (must be column vector)\n",
      "    penalty0    -- (default 10) Initial penalty value (default from LANCELOT)\n",
      "    alpha       -- (default 0.1) defines how aggressively the update_tol is\n",
      "                   reset everytime the penalty is increased. This is a\n",
      "                   heuristic default from LANCELOT.\n",
      "    beta        -- (default 0.9) defines how aggressively the update_tol is\n",
      "                   updated everytime the Lagrange multipliers are updated. This\n",
      "                   is a heuristic default from LANCELOT.\n",
      "    tau         -- (default 10) defines how aggressively to update the penalty.\n",
      "                   This is a heuristic default from LANCELOT.\n",
      "    min_method  -- (default 'L-BFGS-B') see scipy documentation for details. If\n",
      "                   you change this, be sure to choose method that can handle\n",
      "                   high-dimensional parameter spaces and that does not\n",
      "                   interfere with the augmented Lagrangian algorithm (i.e., if\n",
      "                   the method you choose handles the constraints, chances are\n",
      "                   that the algo will not play nice with it). Is handed as\n",
      "                   'method' keyword parameter to scipy.optimize.minimize.\n",
      "    callback    -- (default None) Called after each iteration, as callback(xk),\n",
      "                   where xk is the current parameter vector.\n",
      "    bounds      -- (default None) Bounds for variables (only for L-BFGS-B, TNC\n",
      "                   and SLSQP). (min, max) pairs for each element in x, defining\n",
      "                   the bounds on that parameter. Use None for one of min or max\n",
      "                   when there is no bound in that direction.\n",
      "    jac         -- (default None) Jacobian (gradient) of objective function.\n",
      "                   Only for CG, BFGS, Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg,\n",
      "                   trust-ncg. If jac is a Boolean and is True, fun is assumed\n",
      "                   to return the gradient along with the objective function. If\n",
      "                   False, the gradient will be estimated numerically. jac can\n",
      "                   also be a callable returning the gradient of the objective.\n",
      "                   In this case, it must accept the same arguments as fun.\n",
      "                   R\u207f\u2192R\u207f (must me a column vector)\n",
      "    hess        -- (default None) Hessian (matrix of second-order derivatives)\n",
      "                   of objective function or Hessian of objective function times\n",
      "                   an arbitrary vector p. Only for Newton-CG, dogleg,\n",
      "                   trust-ncg. Only one of hessp or hess needs to be given. If\n",
      "                   hess is provided, then hessp will be ignored. If neither\n",
      "                   hess nor hessp is provided, then the Hessian product will be\n",
      "                   approximated using finite differences on jac. hessp must\n",
      "                   compute the Hessian times an arbitrary vector.\n",
      "                   R\u207f\u2192R\u207f\u02e3\u207f\n",
      "    constraints_jac -- (default None) Jacobian (gradient) of constraints function.\n",
      "                   Only for CG, BFGS, Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg,\n",
      "                   trust-ncg. If jac is a Boolean and is True, fun is assumed\n",
      "                   to return the gradient along with the objective function. If\n",
      "                   False, the gradient will be estimated numerically. jac can\n",
      "                   also be a callable returning the gradient of the objective.\n",
      "                   In this case, it must accept the same arguments as fun.\n",
      "                   R\u207f\u2192R\u1d50\u02e3\u207f\n",
      "    constraints_hess -- (default None) Hessian (matrix of second-order derivatives)\n",
      "                   of constraints function or Hessian of objective function times\n",
      "                   an arbitrary vector p. Only for Newton-CG, dogleg,\n",
      "                   trust-ncg. Only one of hessp or hess needs to be given. If\n",
      "                   hess is provided, then hessp will be ignored. If neither\n",
      "                   hess nor hessp is provided, then the Hessian product will be\n",
      "                   approximated using finite differences on jac. hessp must\n",
      "                   compute the Hessian times an arbitrary vector.\n",
      "                   R\u207f\u2192R\u1d50\u02e3\u207f\u02e3\u207f\n",
      "    store_iterates -- (default None) if set to 'iterate' the full iterates are\n",
      "                   stored in module-level constant iterates\n",
      "    **options   -- are handed through to min_method as is.\n",
      "    \"\"\"\n",
      "    x = x0\n",
      "    mandatory_items = {'outer_maxiter': 20,\n",
      "                       'disp': False}\n",
      "    for key, val in mandatory_items.items():\n",
      "        if not key in options.keys():\n",
      "            options[key] = val\n",
      "\n",
      "    if not isinstance(multiplier0, np.matrix):\n",
      "        raise Exception(\n",
      "            \"for sanity reasons, imma require multiplier0 to be column vector \"\n",
      "            \"of type  np.matrix, even if it's scalar. got a {}\".format(type(multiplier0)))\n",
      "    if multiplier0.shape[1] != 1 or len(multiplier0.shape) != 2:\n",
      "        raise Exception(\n",
      "            \"for sanity reasons, imma require multiplier0 to be column vector \"\n",
      "            \"of type  np.matrix, even if it's scalar\")\n",
      "    multiplier = multiplier0  # 'lam' in the objective\n",
      "    penalty = penalty0        # 'c_pen' in the objective\n",
      "    update_tol0 = penalty**alpha*update_tol0\n",
      "    update_tol = update_tol0/penalty**alpha\n",
      "    current_tol = tol\n",
      "    constraints = constraints['fun']\n",
      "\n",
      "    def mod_objective_no_args(x, lam, c_pen):\n",
      "        \"\"\" Augmented lagrangian of the objective function\n",
      "        Keyword Arguments:\n",
      "        x     -- argument of minimisation\n",
      "        lam   -- current vector of laplace multipliers\n",
      "        c_pen -- current penalty\n",
      "        \"\"\"\n",
      "        x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "        constraints_eval = constraints(x)\n",
      "        return fun(x) + float(lam.T*constraints_eval + c_pen/2*(constraints_eval.T*constraints_eval))\n",
      "\n",
      "    def mod_objective_with_args(x, lam, c_pen, *args):\n",
      "        \"\"\" Augmented lagrangian of the objective function\n",
      "        Keyword Arguments:\n",
      "        x     -- argument of minimisation\n",
      "        lam   -- current vector of laplace multipliers\n",
      "        c_pen -- current penalty\n",
      "        *args -- additional arguments passed to the objective function and its\n",
      "                 derivatives\n",
      "        \"\"\"\n",
      "        x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "        constraints_eval = constraints(x, *args)\n",
      "        return fun(x, *args) + float(lam.T*constraints_eval + c_pen/2*(constraints_eval.T*constraints_eval))\n",
      "\n",
      "    if args:\n",
      "        mod_objective = mod_objective_with_args\n",
      "    else:\n",
      "        mod_objective = mod_objective_no_args\n",
      "\n",
      "    if jac is not None:\n",
      "        if constraints_jac is None:\n",
      "            raise Exception(\"You need to either specify both jac and constraints_jac or none of the two\")\n",
      "        def mod_jac_no_args(x, lam, c_pen):\n",
      "            \"\"\"\n",
      "            jacobian of the augmented lagrangian of the objective function\n",
      "            Keyword Arguments:\n",
      "            x     -- argument of minimisation\n",
      "            lam   -- current vector of laplace multipliers\n",
      "            c_pen -- current penalty\n",
      "            \"\"\"\n",
      "            x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "            constraints_eval = constraints(x)\n",
      "            constraints_jac_eval = constraints_jac(x)\n",
      "            return jac(x) + constraints_jac_eval.T*lam + c_pen * constraints_jac_eval.T*constraints_eval\n",
      "\n",
      "        def mod_jac_with_args(x, lam, c_pen, *args):\n",
      "            \"\"\"\n",
      "            jacobian of the augmented lagrangian of the objective function\n",
      "            Keyword Arguments:\n",
      "            x     -- argument of minimisation\n",
      "            lam   -- current vector of laplace multipliers\n",
      "            c_pen -- current penalty\n",
      "            *args -- additional arguments passed to the objective function and its\n",
      "                     derivatives\n",
      "            \"\"\"\n",
      "            x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "            constraints_eval = constraints(x, *args)\n",
      "            constraints_jac_eval = constraints_jac(x, *args)\n",
      "            return jac(x, *args) + constraints_jac_eval.T*lam + c_pen * constraints_jac_eval.T*constraints_eval\n",
      "\n",
      "        if args:\n",
      "            mod_jac = mod_jac_with_args\n",
      "        else:\n",
      "            mod_jac = mod_jac_no_args\n",
      "    else:\n",
      "        mod_jac = jac\n",
      "\n",
      "    if hess is not None:\n",
      "        if constraints_hess is None:\n",
      "            raise Exception(\"You need to either specify both hess and constraints_hess or none of the two\")\n",
      "        def mod_hess_no_args(x, lam, c_pen):\n",
      "            \"\"\"\n",
      "            jacobian of the augmented lagrangian of the objective function\n",
      "            Keyword Arguments:\n",
      "            x     -- argument of minimisation\n",
      "            lam   -- current vector of laplace multipliers\n",
      "            c_pen -- current penalty\n",
      "            \"\"\"\n",
      "            x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "            constraints_eval = constraints(x)\n",
      "            constraints_jac_eval = constraints_jac(x)\n",
      "            constraints_hess_eval = constraints_hess(x)\n",
      "            return_hess = hess(x) + c_pen * constraints_jac_eval.T*constraints_jac_eval\n",
      "            for i in range(lam.size):\n",
      "                return_hess += (lam[i] + c_pen * constraints_eval[i]) * constraints_hess_eval[i]\n",
      "            return return_hess\n",
      "\n",
      "        def mod_hess_with_args(x, lam, c_pen, *args):\n",
      "            \"\"\"\n",
      "            jacobian of the augmented lagrangian of the objective function\n",
      "            Keyword Arguments:\n",
      "            x     -- argument of minimisation\n",
      "            lam   -- current vector of laplace multipliers\n",
      "            c_pen -- current penalty\n",
      "            *args -- additional arguments passed to the objective function and its\n",
      "                     derivatives\n",
      "            \"\"\"\n",
      "            x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "            constraints_eval = constraints(x, *args)\n",
      "            constraints_jac_eval = constraints_jac(x, *args)\n",
      "            constraints_hess_eval = constraints_hess(x, *args)\n",
      "            return_hess = hess(x, *args) + c_pen * constraints_jac_eval.T*constraints_jac_eval\n",
      "            for i in range(lam.size):\n",
      "                return_hess += (lam[i] * constraints_hess_eval[i] +\n",
      "                                c_pen*constraints_jac_eval * constraints_jac_eval.T)\n",
      "            return return_hess\n",
      "\n",
      "        if args:\n",
      "            mod_hess = mod_hess_with_args\n",
      "        else:\n",
      "            mod_hess = mod_hess_no_args\n",
      "    else:\n",
      "        mod_hess = hess\n",
      "\n",
      "    # some of the option args get duplicated in _minimize.py (annoying design\n",
      "    # choice in scipy)\n",
      "    # del options['bounds']\n",
      "\n",
      "    norm_grad = 2 * tol + 1\n",
      "    norm_constraint = 2 * tol + 1\n",
      "\n",
      "    # LANCELOT algo\n",
      "    counter = 0\n",
      "    inner_options = deepcopy(options)\n",
      "    inner_options['disp']= False\n",
      "    del inner_options['outer_maxiter']\n",
      "    if options['disp']:\n",
      "        print((\"{0[k]} | {0[x]} {0[lam]} {0[c]} {0[cur_tol]} \"\n",
      "               \"{0[update_tol]} {0[nit]}\").format(\n",
      "                   {'k': counter,\n",
      "                    'x': x,\n",
      "                    'lam': multiplier,\n",
      "                    'c': penalty,\n",
      "                    'cur_tol': current_tol,\n",
      "                    'update_tol': update_tol,\n",
      "                    'nit': '?'}))\n",
      "    iterates = list()\n",
      "    if store_iterates == 'iterate':\n",
      "        iterates.append(scipy.optimize.OptimizeResult({'x':np.asarray(x).ravel()}))\n",
      "    try:\n",
      "        while True:\n",
      "            if (norm_grad < tol and norm_constraint < tol):\n",
      "                raise ReachedTolerance((\n",
      "                    \"{0} (norm_grad) < {2} (tol) and {1} (norm_constraint) < \"\n",
      "                    \"{2} (tol)\").format(norm_grad, norm_constraint, tol))\n",
      "            if counter == options['outer_maxiter']:\n",
      "                raise ReachedMaxiter(\"reached maxiter ({})\".format(\n",
      "                    options['outer_maxiter']))\n",
      "\n",
      "            ## evaluate the dual objective function)\n",
      "            iterate = scipy.optimize.minimize(mod_objective, x,\n",
      "                                              args=(multiplier, penalty) + args,\n",
      "                                              method=min_method, tol=current_tol,\n",
      "                                              bounds=bounds, jac=mod_jac, hess=mod_hess,\n",
      "                                              options=inner_options)\n",
      "            if store_iterates == 'iterate':\n",
      "                iterates.append(iterate)\n",
      "            if not iterate.success:\n",
      "                raise FailedIterate(\n",
      "                    (\"evaluation of dual objective function failed with the \"\n",
      "                     \"following message: '{}'. current tolerance is {} The full result is\\n{}\").format(\n",
      "                         iterate.message, current_tol, iterate))\n",
      "            constraints_eval = constraints(x, *args)\n",
      "            norm_constraint = np.sqrt((constraints_eval**2).sum())\n",
      "            norm_grad = np.linalg.norm(iterate.jac)\n",
      "            x = np.matrix(iterate.x, copy=False).reshape((-1, 1))\n",
      "\n",
      "            ## decide whether to update the multipliers or the penalty\n",
      "            if norm_constraint <= update_tol:  # update multipliers\n",
      "                try:\n",
      "                    multiplier += float(penalty * constraints_eval)\n",
      "                except Exception as err:\n",
      "                    print(multiplier, constraints_eval)\n",
      "                    raise\n",
      "                current_tol /= penalty\n",
      "                update_tol /= penalty**beta\n",
      "            else:\n",
      "                penalty *= tau\n",
      "                current_tol = tol/penalty\n",
      "                update_tol = update_tol0/penalty**alpha\n",
      "\n",
      "            # run callback, usually a noop\n",
      "            counter += 1\n",
      "            if callback is not None:\n",
      "                callback(x)\n",
      "\n",
      "            # possibly swamp stdout\n",
      "            if options['disp']:\n",
      "                print((\"{0[k]} | {0[x]} {0[lam]} {0[c]} {0[cur_tol]} \"\n",
      "                       \"{0[update_tol]} {0[nit]}\").format(\n",
      "                           {'k': counter,\n",
      "                            'x': x,\n",
      "                            'lam': multiplier,\n",
      "                            'c': penalty,\n",
      "                            'cur_tol': current_tol,\n",
      "                            'update_tol': update_tol,\n",
      "                            'nit': iterate.nit}))\n",
      "\n",
      "    except (FailedIterate, ReachedMaxiter) as err:\n",
      "        message = str(err)\n",
      "        success = False\n",
      "        print('iterations: {}'.format(counter))\n",
      "    except(ReachedTolerance) as err:\n",
      "        message = str(err)\n",
      "        success = True\n",
      "\n",
      "    result = scipy.optimize.OptimizeResult({'message': message,\n",
      "                                            'success': success,\n",
      "                                            'x': iterate.x,\n",
      "                                            'fun': iterate.fun,\n",
      "                                            'jac': iterate.jac,\n",
      "                                            'nit': counter})\n",
      "    if iterates:\n",
      "        result['iterates'] = iterates\n",
      "\n",
      "    return result\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from PyPyContact.Tools.Optimisation import first_wolfe_condition, second_wolfe_condition, ReachedMaxiterWarning\n",
      "import warnings\n",
      "# implements the line search, p. 273, algo 11.2\n",
      "def line_search(fun, x0, fprime, direction, alpha0, beta1=1e-4, beta2=0.99,\n",
      "                step_factor=3., store_iterates=None, maxiter=40):\n",
      "    \"\"\"\n",
      "    find a step size alpha that satisfies both conditions of Wolfe\n",
      "    Keyword Arguments:\n",
      "    fun         -- objective function to minimize\n",
      "    x0          -- initial guess for solution\n",
      "    fprime      -- Jacobian (gradient) of objective function\n",
      "    direction   -- search direction\n",
      "    alpha0      -- Initial guess for step size\n",
      "    beta1       -- (default 1e-4)\n",
      "    beta2       -- (default 0.99)\n",
      "    step_factor -- (default 3.) step increase when too short\n",
      "    store_iterates -- (default None) if set to 'iterate' the full iterates are\n",
      "                   stored in module-level constant iterates\n",
      "    maxiter     -- (default 20) abort and raise Exception after maxiter is\n",
      "                   reached\n",
      "    \"\"\"\n",
      "    alpha_l = 0\n",
      "    alpha_r = float('inf')\n",
      "    alpha = alpha0\n",
      "\n",
      "    wolfe1 = first_wolfe_condition(fun, x0, fprime, direction, alpha, beta1)\n",
      "    wolfe2 = second_wolfe_condition(x0, fprime, direction, alpha, beta2)\n",
      "\n",
      "    iterates = list()\n",
      "    counter = 0\n",
      "    violation = 0\n",
      "    if store_iterates == 'iterate':\n",
      "        iterate = scipy.optimize.OptimizeResult(\n",
      "            {'x': x0.copy(),\n",
      "             'fun': fun(x0),\n",
      "             'jac': fprime(x0),\n",
      "             'alpha_i': alpha,\n",
      "             'alpha_r': alpha_r,\n",
      "             'alpha_l': alpha_l,\n",
      "             'violation': 0})\n",
      "        iterates.append(iterate)\n",
      "    while not (wolfe1 and wolfe2):\n",
      "        if counter == maxiter:\n",
      "            warnings.warn(\n",
      "                (\"Line search did not converge. Are your jacobians correct? \"\n",
      "                 \"wolfe1 = {}, wolfe2 = {}, alpha = {}, nit = {}.\\n\"\n",
      "                 \"If they are, machine precision has been reached. Currently,\"\n",
      "                 \" progress regarding funval would be {}\").format(\n",
      "                     wolfe1, wolfe2, alpha, counter, float(alpha * fprime(x0).T*direction)),\n",
      "                ReachedMaxiterWarning)\n",
      "            break\n",
      "        if not wolfe1: # step too long\n",
      "            alpha_r = alpha\n",
      "            alpha = .5*(alpha_l + alpha_r)\n",
      "            violation = 1\n",
      "\n",
      "        elif wolfe1 and not wolfe2:\n",
      "            alpha_l = alpha\n",
      "            violation = 2\n",
      "            if np.isfinite(alpha_r):\n",
      "                alpha = .5*(alpha_l + alpha_r)\n",
      "            else:\n",
      "                alpha *= step_factor\n",
      "        wolfe1 = first_wolfe_condition(fun, x0, fprime, direction, alpha, beta1)\n",
      "        wolfe2 = second_wolfe_condition(x0, fprime, direction, alpha, beta2)\n",
      "        if store_iterates == 'iterate':\n",
      "            iterate = scipy.optimize.OptimizeResult(\n",
      "                {'x': x0.copy(),\n",
      "                 'fun': fun(x0),\n",
      "                 'jac': fprime(x0),\n",
      "                 'alpha_i': alpha,\n",
      "                 'alpha_r': alpha_r,\n",
      "                 'alpha_l': alpha_l,\n",
      "                 'violation': violation})\n",
      "            iterates.append(iterate)\n",
      "        counter += 1\n",
      "\n",
      "    result = scipy.optimize.OptimizeResult({'success': True,\n",
      "                                            'x': alpha,\n",
      "                                            'nit': counter,\n",
      "                                            'violation':violation})\n",
      "\n",
      "    if iterates:\n",
      "        result['iterates'] = iterates\n",
      "    return result\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def newton_linesearch(fun, x0, jac, hess, tol, args=(), store_iterates=None, **options):\n",
      "    \"\"\"\n",
      "    see Bierlaire (2006), p. 278\n",
      "    Keyword Arguments:\n",
      "    fun       -- objective function to minimize\n",
      "    x0        -- initial guess for solution\n",
      "    jac       -- Jacobian (gradient) of objective function\n",
      "    hess      -- Hessian (matrix of second-order derivatives) of objective function\n",
      "    tol       -- Tolerance for termination\n",
      "    store_iterates -- (default None) if set to 'iterate' the full iterates are\n",
      "                   stored in module-level constant iterates\n",
      "    **options -- none of those will be used\n",
      "    \"\"\"\n",
      "\n",
      "    x = np.matrix(x0.copy()).reshape((-1, 1))\n",
      "    try:\n",
      "        fprime = jac(x, *args)\n",
      "    except Exception:\n",
      "        print(jac, type(jac))\n",
      "        raise\n",
      "\n",
      "    maxiter_key = 'maxiter'\n",
      "    if maxiter_key not in options.keys():\n",
      "        options[maxiter_key] = 20\n",
      "\n",
      "    linesearch_maxiter_key = 'linesearch_maxiter'\n",
      "\n",
      "    if linesearch_maxiter_key not in options.keys():\n",
      "       options[linesearch_maxiter_key] = 20\n",
      "\n",
      "    counter = 0\n",
      "    iterates = list()\n",
      "    if store_iterates == 'iterate':\n",
      "        iterate = scipy.optimize.OptimizeResult(\n",
      "            {'x': x.copy(),\n",
      "             'fun': fun(x, *args),\n",
      "             'jac': jac(x, *args),\n",
      "             'hess': hess(x, *args),\n",
      "             'tau': float('nan'),\n",
      "             'alpha': float('nan')})\n",
      "        iterates.append(iterate)\n",
      "    if args:\n",
      "        use_fun = lambda x: fun(x, *args)\n",
      "        use_jac = lambda x: jac(x, *args)\n",
      "        use_hess = lambda x: hess(x, *args)\n",
      "    else:\n",
      "        use_fun = fun\n",
      "        use_jac = jac\n",
      "        use_hess = hess\n",
      "    try:\n",
      "        while True:\n",
      "            try:\n",
      "                norm_grad = np.linalg.norm(fprime)\n",
      "            except Exception:\n",
      "                print(fprime)\n",
      "                print(type(fprime))\n",
      "                raise\n",
      "            if norm_grad < tol:\n",
      "                raise ReachedTolerance(\n",
      "                    \"||grad f(x)|| = {} < {} = tol\".format(\n",
      "                        norm_grad, tol))\n",
      "            if counter == options['maxiter']:\n",
      "                raise ReachedMaxiter(\"reached maxiter ({})\".format(\n",
      "                    options['maxiter']))\n",
      "            # 1)\n",
      "            L, tau = modified_cholesky(hess(x, *args))\n",
      "            # 2)\n",
      "            fprime = use_jac(x)\n",
      "            z = np.linalg.solve(L, fprime)\n",
      "            # 3)\n",
      "            d = np.linalg.solve(L.T, -z)\n",
      "            # 4)\n",
      "            result = line_search(use_fun, x, use_jac, d, alpha0=1, maxiter=options[linesearch_maxiter_key])\n",
      "            alpha = result.x\n",
      "            violation = result.violation\n",
      "\n",
      "            # 5)\n",
      "            x += alpha * d\n",
      "            counter += 1\n",
      "\n",
      "            if store_iterates == 'iterate':\n",
      "                iterate = scipy.optimize.OptimizeResult(\n",
      "                    {'x': x.copy(),\n",
      "                     'fun': use_fun(x),\n",
      "                     'jac': use_jac(x),\n",
      "                     'hess': use_hess(x),\n",
      "                     'tau': tau,\n",
      "                     'alpha': alpha})\n",
      "                iterates.append(iterate)\n",
      "\n",
      "\n",
      "    except ReachedMaxiter as err:\n",
      "        message = str(err)\n",
      "        success = False\n",
      "    except(ReachedTolerance) as err:\n",
      "        message = str(err)\n",
      "        success = True\n",
      "\n",
      "    result = scipy.optimize.OptimizeResult({'message': message,\n",
      "                                            'success': success,\n",
      "                                            'x': np.asarray(x).ravel(),\n",
      "                                            'fun': use_fun(x),\n",
      "                                            'jac': use_jac(x),\n",
      "                                            'hess': use_hess(x),\n",
      "                                            'nit': counter})\n",
      "\n",
      "    if iterates:\n",
      "        result['iterates'] = iterates\n",
      "    return result\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dumb_fun(x):\n",
      "    return 2*(x[0, ...]**2 + x[1, ...]**2 - 1) - x[0, ...]\n",
      "\n",
      "Q = np.matrix([[4, 0], [0, 4.]])\n",
      "b = np.matrix([[-1., 0]]).T\n",
      "c = -1.\n",
      "def fun(x):\n",
      "    return .5*x.T*Q*x + x.T*b + c\n",
      "def jac(x):\n",
      "    return(Q*x+b)\n",
      "\n",
      "def hess(x):\n",
      "    return Q\n",
      "\n",
      "cQ = .5*Q\n",
      "cb = np.matrix(((0, 0.))).T\n",
      "cc = -1.\n",
      "def constraint(x):\n",
      "    return .5*x.T*cQ*x + x.T*cb + cc\n",
      "def constraint_jac(x):\n",
      "    return (cQ*x + cb).T\n",
      "def constraint_hess(x):\n",
      "    return Q\n",
      "\n",
      "tol = 1.e-2\n",
      "print(constraint_jac(np.matrix(([-1], [.1]))))\n",
      "\n",
      "multiplier0 = np.matrix(((0.)))\n",
      "print(\"multiplier0 = {}\".format(multiplier0))\n",
      "maxiter=1000\n",
      "result = scipy.optimize.minimize(fun, x0=np.matrix(([-1], [.1])),\n",
      "       \t                         constraints={'type':'eq','fun':constraint},\n",
      "\t                             method=augmented_lagrangian, tol=tol,\n",
      "\t                             options={'multiplier0': multiplier0,\n",
      "                                          'store_iterates': 'iterate',\n",
      "                                          'maxiter':maxiter,\n",
      "                                          'outer_maxiter':maxiter})\n",
      "print(\"multiplier0 = {}\".format(multiplier0))\n",
      "print('success = {}'.format(result.success))\n",
      "if not result.success:\n",
      "    print(result.message)\n",
      "from PyPyContact.Tools.Optimisation import modified_cholesky\n",
      "\n",
      "\n",
      "multiplier0 = np.matrix(((0.)))\n",
      "result2 = scipy.optimize.minimize(fun, x0=np.array(([-1], [.1])), jac=jac,\n",
      "                                  hess=hess,\n",
      "       \t                          constraints={'type':'eq','fun':constraint},\n",
      "\t                              method=augmented_lagrangian, tol=tol,\n",
      "\t                              options={'multiplier0': multiplier0,\n",
      "                                           'store_iterates': 'iterate',\n",
      "                                           'min_method':newton_linesearch,\n",
      "                                           'maxiter':maxiter,\n",
      "                                           'outer_maxiter':maxiter,\n",
      "                                           'constraints_jac': constraint_jac,\n",
      "                                           'constraints_hess': constraint_hess,\n",
      "                                           'linesearch_maxiter':8,\n",
      "                                           'penalty0':10,\n",
      "                                           'beta1':.5})\n",
      "print(result2.success)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-2.   0.2]]\n",
        "multiplier0 = [[ 0.]]\n",
        "multiplier0 = [[-25.95639127]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "success = True\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:50: ReachedMaxiterWarning: Line search did not converge. Are your jacobians correct? wolfe1 = False, wolfe2 = False, alpha = 0.00390625, nit = 8.\n",
        "If they are, machine precision has been reached. Currently, progress regarding funval would be -4.0742823982113244e-20\n",
        "-c:50: ReachedMaxiterWarning: Line search did not converge. Are your jacobians correct? wolfe1 = False, wolfe2 = False, alpha = 0.00390625, nit = 8.\n",
        "If they are, machine precision has been reached. Currently, progress regarding funval would be -2.299301674810865e-20\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "iterates = np.array([iterate.x for iterate in result.iterates])\n",
      "print(iterates)\n",
      "res = 51\n",
      "x, y = np.linspace(-1.1, 1.1, res), np.linspace(-1.1, 1.1, res)\n",
      "X, Y = np.meshgrid(x, y)\n",
      "XY = np.zeros((2, res, res))\n",
      "XY[0, ...] = X\n",
      "XY[1, ...] = Y\n",
      "Z = dumb_fun(XY)\n",
      "phi = np.linspace(0, 2*np.pi, 97)\n",
      "plt.contour(X, Y, Z)\n",
      "x, y = np.cos(phi), np.sin(phi)\n",
      "plt.plot(x, y, c='k', lw=2)\n",
      "plt.plot(iterates[:, 0], iterates[:, 1], c='r', ls='--', lw=2)\n",
      "iterates = np.array([iterate.x for iterate in result2.iterates])\n",
      "plt.plot(iterates[:, 0], iterates[:, 1], c='r', lw=2)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ -1.00000000e+00   1.00000000e-01]\n",
        " [ -8.48710737e-01   9.08758534e-02]\n",
        " [ -8.56420335e-01   1.11009482e-01]\n",
        " [ -9.78514902e-01   1.28266109e-01]\n",
        " [ -9.90217789e-01   1.29899582e-01]\n",
        " [  1.01215145e+00   5.16501409e-07]]\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f3841870198>]"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f3841a0aa90>"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "Reproducing the example exactly"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sympy\n",
      "\n",
      "x1 = sympy.Symbol('x1', real=True)\n",
      "x2 = sympy.Symbol('x2', real=True)\n",
      "\n",
      "f = 2*(x1**2 + x2**2 -1) -x1\n",
      "h = x1**2 + x2**2 -1\n",
      "h2 = h**2"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = sympy.Matrix(((sympy.diff(f, x1),),(sympy.diff(f, x2),)))\n",
      "sympy.pprint(df)\n",
      "dh = sympy.Matrix(((sympy.diff(h, x1),),(sympy.diff(h, x2),)))\n",
      "sympy.pprint(dh)\n",
      "dh2 = sympy.Matrix(((sympy.diff(h2, x1),),(sympy.diff(h2, x2),)))\n",
      "sympy.pprint(dh2)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u23a14\u22c5x\u2081 - 1\u23a4\n",
        "\u23a2        \u23a5\n",
        "\u23a3  4\u22c5x\u2082  \u23a6\n",
        "\u23a12\u22c5x\u2081\u23a4\n",
        "\u23a2    \u23a5\n",
        "\u23a32\u22c5x\u2082\u23a6\n",
        "\u23a1     \u239b  2     2    \u239e\u23a4\n",
        "\u23a24\u22c5x\u2081\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0\u23a5\n",
        "\u23a2                    \u23a5\n",
        "\u23a2     \u239b  2     2    \u239e\u23a5\n",
        "\u23a34\u22c5x\u2082\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0\u23a6\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ddf = sympy.Matrix([[sympy.diff(df[0], x1), sympy.diff(df[0], x2)],[sympy.diff(df[1], x1), sympy.diff(df[1], x2)]])\n",
      "sympy.pprint(ddf)\n",
      "ddh = sympy.Matrix([[sympy.diff(dh[0], x1), sympy.diff(dh[0], x2)],[sympy.diff(dh[1], x1), sympy.diff(dh[1], x2)]])\n",
      "sympy.pprint(ddh)\n",
      "ddh2 = sympy.Matrix([[sympy.diff(dh2[0], x1), sympy.diff(dh2[0], x2)],[sympy.diff(dh2[1], x1), sympy.diff(dh2[1], x2)]])\n",
      "sympy.pprint(ddh2)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u23a14  0\u23a4\n",
        "\u23a2    \u23a5\n",
        "\u23a30  4\u23a6\n",
        "\u23a12  0\u23a4\n",
        "\u23a2    \u23a5\n",
        "\u23a30  2\u23a6\n",
        "\u23a1     2       2                        \u23a4\n",
        "\u23a212\u22c5x\u2081  + 4\u22c5x\u2082  - 4       8\u22c5x\u2081\u22c5x\u2082      \u23a5\n",
        "\u23a2                                      \u23a5\n",
        "\u23a2                        2        2    \u23a5\n",
        "\u23a3     8\u22c5x\u2081\u22c5x\u2082        4\u22c5x\u2081  + 12\u22c5x\u2082  - 4\u23a6\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lam, c = sympy.Symbol('\u03bb', real=True), sympy.Symbol('c', real=True)\n",
      "\n",
      "L = f + lam*h + c/2*h2\n",
      "dL = sympy.Matrix([[sympy.diff(L, x1)], [sympy.diff(L, x2)]])\n",
      "sympy.pprint(dL)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u23a1       \u239b  2     2    \u239e                    \u23a4\n",
        "\u23a22\u22c5c\u22c5x\u2081\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0 + 2\u22c5x\u2081\u22c5\u03bb + 4\u22c5x\u2081 - 1\u23a5\n",
        "\u23a2                                          \u23a5\n",
        "\u23a2         \u239b  2     2    \u239e                  \u23a5\n",
        "\u23a3  2\u22c5c\u22c5x\u2082\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0 + 2\u22c5x\u2082\u22c5\u03bb + 4\u22c5x\u2082  \u23a6\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ddL = sympy.Matrix([[sympy.diff(dL[0], x1), sympy.diff(dL[0], x2)], [sympy.diff(dL[1], x1), sympy.diff(dL[1], x2)]])\n",
      "sympy.pprint(ddL)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u23a1      2       \u239b  2     2    \u239e                                                \n",
        "\u23a24\u22c5c\u22c5x\u2081  + 2\u22c5c\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0 + 2\u22c5\u03bb + 4                 4\u22c5c\u22c5x\u2081\u22c5x\u2082            \n",
        "\u23a2                                                                             \n",
        "\u23a2                                               2       \u239b  2     2    \u239e       \n",
        "\u23a3               4\u22c5c\u22c5x\u2081\u22c5x\u2082                 4\u22c5c\u22c5x\u2082  + 2\u22c5c\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0 + 2\u22c5\u03bb \n",
        "\n",
        "   \u23a4\n",
        "   \u23a5\n",
        "   \u23a5\n",
        "   \u23a5\n",
        "+ 4\u23a6\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "source": [
      "Simple bounded example\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "x0=np.array(([0], [1]))\n",
      "slope = -1.\n",
      "sQ = np.matrix([[0, 0], [0, 0.]])\n",
      "b = np.matrix([[slope, 0]]).T\n",
      "c = 0.\n",
      "def sfun(x):\n",
      "    return float(.5*x.T*sQ*x + x.T*b + c)\n",
      "def sjac(x):\n",
      "    return sQ*x + b\n",
      "def shess(x):\n",
      "    return sQ\n",
      "shQ = np.matrix([[0, 0], [0, 2.]])\n",
      "shb = np.matrix([[1., 0]]).T\n",
      "shc = -1.\n",
      "\n",
      "def shfun(x):\n",
      "    return float(.5*x.T*shQ*x + x.T*shb + shc)\n",
      "def shjac(x):\n",
      "    return (shQ*x + shb).T\n",
      "def shhess(x):\n",
      "    return shQ\n",
      "tol = .01\n",
      "maxiter=1000\n",
      "result = scipy.optimize.minimize(fun, x0, jac=jac,\n",
      "                                 hess=hess,\n",
      "       \t                         constraints={'type':'eq','fun':constraint},\n",
      "\t                             method=augmented_lagrangian, tol=tol,\n",
      "\t                             options={'multiplier0': multiplier0,\n",
      "                                          'store_iterates': 'iterate',\n",
      "                                          'min_method':newton_linesearch,\n",
      "                                          'maxiter':maxiter,\n",
      "                                          'outer_maxiter':maxiter,\n",
      "                                          'constraints_jac': constraint_jac,\n",
      "                                          'constraints_hess': constraint_hess,\n",
      "                                          'linesearch_maxiter':20,\n",
      "                                          'penalty0':10})\n",
      "print(result.message)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.009634589379891177 (norm_grad) < 0.01 (tol) and 0.0 (norm_constraint) < 0.01 (tol)\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(result.success)\n",
      "print(result.message)\n",
      "print(result.x)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "0.009634589379891177 (norm_grad) < 0.01 (tol) and 0.0 (norm_constraint) < 0.01 (tol)\n",
        "[ 10.7936248    0.04855352]\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(result.x)\n",
      "print(shfun(np.matrix(result.x).T))"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  9.93564267e-01   2.54422077e-11]\n",
        "-0.006435733054635184\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}