{
 "metadata": {
  "name": "",
  "signature": "sha256:e8fa0ae17d853cb35dc69bdb02e88f527b0a3c0a83305268b8958d19ae574a32"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "source": [
      "Testing the Augmented Lagrangian of PyPyContact"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "The implementation of the augmented Lagrangian in PyPyContact.Tools follows closely the description of the `LANCELOT` algorithm described in Bierlaire (2006)"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "The function `augmented_lagrangian` has the form of custom minimizer for [scipy.optimize.minimize](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.minimize.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import os\n",
      "import numpy as np\n",
      "\n",
      "import scipy.optimize\n",
      "import scipy\n",
      "sys.path.append(os.path.join(os.getcwd(), \"../PyPyContact/Tools/\"))\n",
      "#from AugmentedLagrangian import augmented_lagrangian"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "Book example"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "Example 20.5: Minimise the fuction $f(x)$\n",
      "$$\\min_{x\\in\\mathbb{R}^2} 2(x_1^2+x_2^2 -1)-x_1$$\n",
      "under the constraint\n",
      "$$ x_1^2 + x_2^2 = 1$$"
     ]
    },
    {
     "cell_type": "markdown",
     "source": [
      "ugly workaround to get a fresh AugmentedLagrangian without module loads"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fname = \"../PyPyContact/Tools/AugmentedLagrangian.py\"\n",
      "#with open(fname) as filehandle:\n",
      "#    content = ''.join((line for line in filehandle))\n",
      "#exec(content)\n",
      "from PyPyContact.Tools.Optimisation import augmented_lagrangian\n",
      "from copy import deepcopy\n",
      "from PyPyContact.Tools.Optimisation import ReachedTolerance, ReachedMaxiter, FailedIterate\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# implemented as a custom minimizer for scipy\n",
      "def augmented_lagrangian(fun, x0, args=(), constraints=None, tol=1e-5,\n",
      "                         update_tol0=.1, multiplier0=None, penalty0=10, alpha=0.1,\n",
      "                         beta=0.9, tau=10, min_method='L-BFGS-B', callback=None,\n",
      "                         bounds=None, jac=None, hess=None, constraints_jac=None,\n",
      "                         constraints_hess=None,\n",
      "                         hessp=None, store_iterates=None, **options):\n",
      "    \"\"\"\n",
      "    Custom minimizer that implements the LANCELOT (Conn et al., 1992) augmented\n",
      "    Lagrangian minimizer. For documentation, see Bierlaire (2006)\n",
      "\n",
      "\n",
      "    Bierlaire (2006):\n",
      "    Introduction \u00e0 l'optimization diff\u00e9rentiable, Michel Bierlaire, Presses\n",
      "    polytechniques et universitaires romandes, Lausanne 2006,\n",
      "    ISBN:2-88074-669-8\n",
      "\n",
      "    Keyword Arguments:\n",
      "    fun         -- objective function to minimize. R\u207f\u2192R\n",
      "    x0          -- initial guess for solution, x0 in R\u207f\n",
      "    args        -- (default empty) additional arguments that need to be fed to fun\n",
      "    constraints -- (default None) not optional. An exception will be raised if\n",
      "                   this is not specified. A callable that is called as\n",
      "                   constraints(x, args=args) and returns an ndarray of same\n",
      "                   length as multiplier0. R\u207f\u2192R\u1d50\n",
      "    tol         -- (default None) Convergence tolerance. Is used for both the\n",
      "                   subjacent minimizer as well as for the outer (augmented\n",
      "                   Lagrangian) loop.\n",
      "    update_tol0 -- (default .1) This value is used to decide whether the\n",
      "                   minimum x_k is \"sufficiently\" admissible: if\n",
      "                   ||constraints(x_k, args=args)|| < current update_tol, then\n",
      "                   the multipliers are updated, else the penalty is increased.\n",
      "    multiplier0 -- (default None) Initial guess for the Lagrange multipliers. in R\u1d50 (must be column vector)\n",
      "    penalty0    -- (default 10) Initial penalty value (default from LANCELOT)\n",
      "    alpha       -- (default 0.1) defines how aggressively the update_tol is\n",
      "                   reset everytime the penalty is increased. This is a\n",
      "                   heuristic default from LANCELOT.\n",
      "    beta        -- (default 0.9) defines how aggressively the update_tol is\n",
      "                   updated everytime the Lagrange multipliers are updated. This\n",
      "                   is a heuristic default from LANCELOT.\n",
      "    tau         -- (default 10) defines how aggressively to update the penalty.\n",
      "                   This is a heuristic default from LANCELOT.\n",
      "    min_method  -- (default 'L-BFGS-B') see scipy documentation for details. If\n",
      "                   you change this, be sure to choose method that can handle\n",
      "                   high-dimensional parameter spaces and that does not\n",
      "                   interfere with the augmented Lagrangian algorithm (i.e., if\n",
      "                   the method you choose handles the constraints, chances are\n",
      "                   that the algo will not play nice with it). Is handed as\n",
      "                   'method' keyword parameter to scipy.optimize.minimize.\n",
      "    callback    -- (default None) Called after each iteration, as callback(xk),\n",
      "                   where xk is the current parameter vector.\n",
      "    bounds      -- (default None) Bounds for variables (only for L-BFGS-B, TNC\n",
      "                   and SLSQP). (min, max) pairs for each element in x, defining\n",
      "                   the bounds on that parameter. Use None for one of min or max\n",
      "                   when there is no bound in that direction.\n",
      "    jac         -- (default None) Jacobian (gradient) of objective function.\n",
      "                   Only for CG, BFGS, Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg,\n",
      "                   trust-ncg. If jac is a Boolean and is True, fun is assumed\n",
      "                   to return the gradient along with the objective function. If\n",
      "                   False, the gradient will be estimated numerically. jac can\n",
      "                   also be a callable returning the gradient of the objective.\n",
      "                   In this case, it must accept the same arguments as fun.\n",
      "                   R\u207f\u2192R\u207f (must me a column vector)\n",
      "    hess        -- (default None) Hessian (matrix of second-order derivatives)\n",
      "                   of objective function or Hessian of objective function times\n",
      "                   an arbitrary vector p. Only for Newton-CG, dogleg,\n",
      "                   trust-ncg. Only one of hessp or hess needs to be given. If\n",
      "                   hess is provided, then hessp will be ignored. If neither\n",
      "                   hess nor hessp is provided, then the Hessian product will be\n",
      "                   approximated using finite differences on jac. hessp must\n",
      "                   compute the Hessian times an arbitrary vector.\n",
      "                   R\u207f\u2192R\u207f\u02e3\u207f\n",
      "    constraints_jac -- (default None) Jacobian (gradient) of constraints function.\n",
      "                   Only for CG, BFGS, Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg,\n",
      "                   trust-ncg. If jac is a Boolean and is True, fun is assumed\n",
      "                   to return the gradient along with the objective function. If\n",
      "                   False, the gradient will be estimated numerically. jac can\n",
      "                   also be a callable returning the gradient of the objective.\n",
      "                   In this case, it must accept the same arguments as fun.\n",
      "                   R\u207f\u2192R\u1d50\u02e3\u207f\n",
      "    constraints_hess -- (default None) Hessian (matrix of second-order derivatives)\n",
      "                   of constraints function or Hessian of objective function times\n",
      "                   an arbitrary vector p. Only for Newton-CG, dogleg,\n",
      "                   trust-ncg. Only one of hessp or hess needs to be given. If\n",
      "                   hess is provided, then hessp will be ignored. If neither\n",
      "                   hess nor hessp is provided, then the Hessian product will be\n",
      "                   approximated using finite differences on jac. hessp must\n",
      "                   compute the Hessian times an arbitrary vector.\n",
      "                   R\u207f\u2192R\u1d50\u02e3\u207f\u02e3\u207f\n",
      "    store_iterates -- (default None) if set to 'iterate' the full iterates are\n",
      "                   stored in module-level constant iterates\n",
      "    **options   -- are handed through to min_method as is.\n",
      "    \"\"\"\n",
      "    x = x0\n",
      "    mandatory_items = {'outer_maxiter': 20,\n",
      "                       'disp': False}\n",
      "    for key, val in mandatory_items.items():\n",
      "        if not key in options.keys():\n",
      "            options[key] = val\n",
      "\n",
      "    if not isinstance(multiplier0, np.matrix):\n",
      "        raise Exception(\n",
      "            \"for sanity reasons, imma require multiplier0 to be column vector \"\n",
      "            \"of type  np.matrix, even if it's scalar. got a {}\".format(type(multiplier0)))\n",
      "    if multiplier0.shape[1] != 1 or len(multiplier0.shape) != 2:\n",
      "        raise Exception(\n",
      "            \"for sanity reasons, imma require multiplier0 to be column vector \"\n",
      "            \"of type  np.matrix, even if it's scalar\")\n",
      "    multiplier = multiplier0  # 'lam' in the objective\n",
      "    penalty = penalty0        # 'c_pen' in the objective\n",
      "    update_tol0 = penalty**alpha*update_tol0\n",
      "    update_tol = update_tol0/penalty**alpha\n",
      "    current_tol = tol\n",
      "    constraints = constraints['fun']\n",
      "\n",
      "    def mod_objective_no_args(x, lam, c_pen):\n",
      "        \"\"\" Augmented lagrangian of the objective function\n",
      "        Keyword Arguments:\n",
      "        x     -- argument of minimisation\n",
      "        lam   -- current vector of laplace multipliers\n",
      "        c_pen -- current penalty\n",
      "        \"\"\"\n",
      "        x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "        constraints_eval = constraints(x)\n",
      "        return fun(x) + float(lam.T*constraints_eval + c_pen/2*(constraints_eval.T*constraints_eval))\n",
      "\n",
      "    def mod_objective_with_args(x, lam, c_pen, *args):\n",
      "        \"\"\" Augmented lagrangian of the objective function\n",
      "        Keyword Arguments:\n",
      "        x     -- argument of minimisation\n",
      "        lam   -- current vector of laplace multipliers\n",
      "        c_pen -- current penalty\n",
      "        *args -- additional arguments passed to the objective function and its\n",
      "                 derivatives\n",
      "        \"\"\"\n",
      "        x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "        constraints_eval = constraints(x, *args)\n",
      "        return fun(x, *args) + float(lam.T*constraints_eval + c_pen/2*(constraints_eval.T*constraints_eval))\n",
      "\n",
      "    if args:\n",
      "        mod_objective = mod_objective_with_args\n",
      "    else:\n",
      "        mod_objective = mod_objective_no_args\n",
      "\n",
      "    if jac is not None:\n",
      "        if constraints_jac is None:\n",
      "            raise Exception(\"You need to either specify both jac and constraints_jac or none of the two\")\n",
      "        def mod_jac_no_args(x, lam, c_pen):\n",
      "            \"\"\"\n",
      "            jacobian of the augmented lagrangian of the objective function\n",
      "            Keyword Arguments:\n",
      "            x     -- argument of minimisation\n",
      "            lam   -- current vector of laplace multipliers\n",
      "            c_pen -- current penalty\n",
      "            \"\"\"\n",
      "            x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "            constraints_eval = constraints(x)\n",
      "            constraints_jac_eval = constraints_jac(x)\n",
      "            return jac(x) + constraints_jac_eval.T*lam + c_pen * constraints_jac_eval.T*constraints_eval\n",
      "\n",
      "        def mod_jac_with_args(x, lam, c_pen, *args):\n",
      "            \"\"\"\n",
      "            jacobian of the augmented lagrangian of the objective function\n",
      "            Keyword Arguments:\n",
      "            x     -- argument of minimisation\n",
      "            lam   -- current vector of laplace multipliers\n",
      "            c_pen -- current penalty\n",
      "            *args -- additional arguments passed to the objective function and its\n",
      "                     derivatives\n",
      "            \"\"\"\n",
      "            x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "            constraints_eval = constraints(x, *args)\n",
      "            constraints_jac_eval = constraints_jac(x, *args)\n",
      "            return jac(x, *args) + constraints_jac_eval.T*lam + c_pen * constraints_jac_eval.T*constraints_eval\n",
      "\n",
      "        if args:\n",
      "            mod_jac = mod_jac_with_args\n",
      "        else:\n",
      "            mod_jac = mod_jac_no_args\n",
      "    else:\n",
      "        mod_jac = jac\n",
      "\n",
      "    if hess is not None:\n",
      "        if constraints_hess is None:\n",
      "            raise Exception(\"You need to either specify both hess and constraints_hess or none of the two\")\n",
      "        def mod_hess_no_args(x, lam, c_pen):\n",
      "            \"\"\"\n",
      "            jacobian of the augmented lagrangian of the objective function\n",
      "            Keyword Arguments:\n",
      "            x     -- argument of minimisation\n",
      "            lam   -- current vector of laplace multipliers\n",
      "            c_pen -- current penalty\n",
      "            \"\"\"\n",
      "            x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "            constraints_eval = constraints(x)\n",
      "            constraints_jac_eval = constraints_jac(x)\n",
      "            constraints_hess_eval = constraints_hess(x)\n",
      "            return_hess = hess(x) + c_pen * constraints_jac_eval.T*constraints_jac_eval\n",
      "            for i in range(lam.size):\n",
      "                return_hess += (lam[i] + c_pen * constraints_eval[i]) * constraints_hess_eval[i]\n",
      "            return return_hess\n",
      "\n",
      "        def mod_hess_with_args(x, lam, c_pen, *args):\n",
      "            \"\"\"\n",
      "            jacobian of the augmented lagrangian of the objective function\n",
      "            Keyword Arguments:\n",
      "            x     -- argument of minimisation\n",
      "            lam   -- current vector of laplace multipliers\n",
      "            c_pen -- current penalty\n",
      "            *args -- additional arguments passed to the objective function and its\n",
      "                     derivatives\n",
      "            \"\"\"\n",
      "            x = np.matrix(x, copy=False).reshape((-1, 1))\n",
      "            constraints_eval = constraints(x, *args)\n",
      "            constraints_jac_eval = constraints_jac(x, *args)\n",
      "            constraints_hess_eval = constraints_hess(x, *args)\n",
      "            return_hess = hess(x, *args) + c_pen * constraints_jac_eval.T*constraints_jac_eval\n",
      "            for i in range(lam.size):\n",
      "                return_hess += (lam[i] * constraints_hess_eval[i] +\n",
      "                                c_pen*constraints_jac_eval * constraints_jac_eval.T)\n",
      "            return return_hess\n",
      "\n",
      "        if args:\n",
      "            mod_hess = mod_hess_with_args\n",
      "        else:\n",
      "            mod_hess = mod_hess_no_args\n",
      "    else:\n",
      "        mod_hess = hess\n",
      "\n",
      "    # some of the option args get duplicated in _minimize.py (annoying design\n",
      "    # choice in scipy)\n",
      "    # del options['bounds']\n",
      "\n",
      "    norm_grad = 2 * tol + 1\n",
      "    norm_constraint = 2 * tol + 1\n",
      "\n",
      "    # LANCELOT algo\n",
      "    counter = 0\n",
      "    inner_options = deepcopy(options)\n",
      "    inner_options['disp']= False\n",
      "    del inner_options['outer_maxiter']\n",
      "    if options['disp']:\n",
      "        print((\"{0[k]} | {0[x]} {0[lam]} {0[c]} {0[cur_tol]} \"\n",
      "               \"{0[update_tol]} {0[nit]}\").format(\n",
      "                   {'k': counter,\n",
      "                    'x': x,\n",
      "                    'lam': multiplier,\n",
      "                    'c': penalty,\n",
      "                    'cur_tol': current_tol,\n",
      "                    'update_tol': update_tol,\n",
      "                    'nit': '?'}))\n",
      "    iterates = list()\n",
      "    if store_iterates == 'iterate':\n",
      "        iterates.append(scipy.optimize.OptimizeResult({'x':np.asarray(x).ravel()}))\n",
      "    try:\n",
      "        while True:\n",
      "            if (norm_grad < tol and norm_constraint < tol):\n",
      "                raise ReachedTolerance((\n",
      "                    \"{0} (norm_grad) < {2} (tol) and {1} (norm_constraint) < \"\n",
      "                    \"{2} (tol)\").format(norm_grad, norm_constraint, tol))\n",
      "            if counter == options['outer_maxiter']:\n",
      "                raise ReachedMaxiter(\"reached maxiter ({})\".format(\n",
      "                    options['outer_maxiter']))\n",
      "\n",
      "            ## evaluate the dual objective function)\n",
      "            iterate = scipy.optimize.minimize(mod_objective, x,\n",
      "                                              args=(multiplier, penalty) + args,\n",
      "                                              method=min_method, tol=current_tol,\n",
      "                                              bounds=bounds, jac=mod_jac, hess=mod_hess,\n",
      "                                              options=inner_options)\n",
      "            if store_iterates == 'iterate':\n",
      "                iterates.append(iterate)\n",
      "            if not iterate.success:\n",
      "                raise FailedIterate(\n",
      "                    (\"evaluation of dual objective function failed with the \"\n",
      "                     \"following message: '{}'. current tolerance is {} The full result is\\n{}\").format(\n",
      "                         iterate.message, current_tol, iterate))\n",
      "            constraints_eval = constraints(x, *args)\n",
      "            norm_constraint = np.sqrt((constraints_eval**2).sum())\n",
      "            norm_grad = np.linalg.norm(iterate.jac)\n",
      "            x = np.matrix(iterate.x, copy=False).reshape((-1, 1))\n",
      "\n",
      "            ## decide whether to update the multipliers or the penalty\n",
      "            if norm_constraint <= update_tol:  # update multipliers\n",
      "                try:\n",
      "                    multiplier += float(penalty * constraints_eval)\n",
      "                except Exception as err:\n",
      "                    print(multiplier, constraints_eval)\n",
      "                    raise\n",
      "                current_tol /= penalty\n",
      "                update_tol /= penalty**beta\n",
      "            else:\n",
      "                penalty *= tau\n",
      "                current_tol = tol/penalty\n",
      "                update_tol = update_tol0/penalty**alpha\n",
      "\n",
      "            # run callback, usually a noop\n",
      "            counter += 1\n",
      "            if callback is not None:\n",
      "                callback(x)\n",
      "\n",
      "            # possibly swamp stdout\n",
      "            if options['disp']:\n",
      "                print((\"{0[k]} | {0[x]} {0[lam]} {0[c]} {0[cur_tol]} \"\n",
      "                       \"{0[update_tol]} {0[nit]}\").format(\n",
      "                           {'k': counter,\n",
      "                            'x': x,\n",
      "                            'lam': multiplier,\n",
      "                            'c': penalty,\n",
      "                            'cur_tol': current_tol,\n",
      "                            'update_tol': update_tol,\n",
      "                            'nit': iterate.nit}))\n",
      "\n",
      "    except (FailedIterate, ReachedMaxiter) as err:\n",
      "        message = str(err)\n",
      "        success = False\n",
      "        print('iterations: {}'.format(counter))\n",
      "        raise\n",
      "    except(ReachedTolerance) as err:\n",
      "        message = str(err)\n",
      "        success = True\n",
      "\n",
      "    result = scipy.optimize.OptimizeResult({'message': message,\n",
      "                                            'success': success,\n",
      "                                            'x': iterate.x,\n",
      "                                            'fun': iterate.fun,\n",
      "                                            'jac': iterate.jac,\n",
      "                                            'nit': counter})\n",
      "    if iterates:\n",
      "        result['iterates'] = iterates\n",
      "\n",
      "    return result\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def newton_linesearch(fun, x0, jac, hess, tol, args=(), store_iterates=None, **options):\n",
      "    \"\"\"\n",
      "    see Bierlaire (2006), p. 278\n",
      "    Keyword Arguments:\n",
      "    fun       -- objective function to minimize\n",
      "    x0        -- initial guess for solution\n",
      "    jac       -- Jacobian (gradient) of objective function\n",
      "    hess      -- Hessian (matrix of second-order derivatives) of objective function\n",
      "    tol       -- Tolerance for termination\n",
      "    store_iterates -- (default None) if set to 'iterate' the full iterates are\n",
      "                   stored in module-level constant iterates\n",
      "    **options -- none of those will be used\n",
      "    \"\"\"\n",
      "\n",
      "    x = np.matrix(x0.copy()).reshape((-1, 1))\n",
      "    try:\n",
      "        fprime = jac(x, *args)\n",
      "    except Exception:\n",
      "        print(jac, type(jac))\n",
      "        raise\n",
      "\n",
      "    maxiter_key = 'maxiter'\n",
      "    if maxiter_key not in options.keys():\n",
      "        options[maxiter_key] = 20\n",
      "\n",
      "    counter = 0\n",
      "    iterates = list()\n",
      "    if store_iterates == 'iterate':\n",
      "        iterate = scipy.optimize.OptimizeResult(\n",
      "            {'x': x.copy(),\n",
      "             'fun': fun(x, *args),\n",
      "             'jac': jac(x, *args),\n",
      "             'hess': hess(x, *args),\n",
      "             'tau': float('nan'),\n",
      "             'alpha': float('nan')})\n",
      "        iterates.append(iterate)\n",
      "    if args:\n",
      "        use_fun = lambda x: fun(x, *args)\n",
      "        use_jac = lambda x: jac(x, *args)\n",
      "        use_hess = lambda x: hess(x, *args)\n",
      "    else:\n",
      "        use_fun = fun\n",
      "        use_jac = jac\n",
      "        use_hess = hess\n",
      "    try:\n",
      "        while True:\n",
      "            norm_grad = np.linalg.norm(fprime)\n",
      "            if norm_grad < tol:\n",
      "                raise ReachedTolerance(\n",
      "                    \"||grad f(x)|| = {} < {} = tol\".format(\n",
      "                        norm_grad, tol))\n",
      "            if counter == options['maxiter']:\n",
      "                raise ReachedMaxiter(\"reached maxiter ({})\".format(\n",
      "                    options['maxiter']))\n",
      "            # 1)\n",
      "            L, tau = modified_cholesky(hess(x, *args))\n",
      "            # 2)\n",
      "            fprime = use_jac(x)\n",
      "            z = np.linalg.solve(L, fprime)\n",
      "            # 3)\n",
      "            d = np.linalg.solve(L.T, -z)\n",
      "            # 4)\n",
      "            result = line_search(use_fun, x, use_jac, d, alpha0 = 1)\n",
      "            alpha = result.x\n",
      "            violation = result.violation\n",
      "\n",
      "            # 5)\n",
      "            x += alpha * d\n",
      "            counter += 1\n",
      "\n",
      "            if store_iterates == 'iterate':\n",
      "                iterate = scipy.optimize.OptimizeResult(\n",
      "                    {'x': x.copy(),\n",
      "                     'fun': use_fun(x),\n",
      "                     'jac': use_jac(x),\n",
      "                     'hess': use_hess(x),\n",
      "                     'tau': tau,\n",
      "                     'alpha': alpha})\n",
      "                iterates.append(iterate)\n",
      "\n",
      "\n",
      "    except ReachedMaxiter as err:\n",
      "        message = str(err)\n",
      "        success = False\n",
      "    except(ReachedTolerance) as err:\n",
      "        message = str(err)\n",
      "        success = True\n",
      "\n",
      "    result = scipy.optimize.OptimizeResult({'message': message,\n",
      "                                            'success': success,\n",
      "                                            'x': np.asarray(x).ravel(),\n",
      "                                            'fun': use_fun(x),\n",
      "                                            'jac': use_jac(x),\n",
      "                                            'hess': use_hess(x),\n",
      "                                            'nit': counter})\n",
      "\n",
      "    if iterates:\n",
      "        result['iterates'] = iterates\n",
      "    return result\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fun(x):\n",
      "    return 2*(x[0, ...]**2 + x[1, ...]**2 - 1) - x[0, ...]\n",
      "\n",
      "Q = np.matrix([[4, 0], [0, 4.]])\n",
      "b = np.matrix([[-1., 0]]).T\n",
      "c = -1.\n",
      "def fun(x):\n",
      "    return .5*x.T*Q*x + x.T*b + c\n",
      "def jac(x):\n",
      "    return(Q*x+b)\n",
      "\n",
      "def hess(x):\n",
      "    return Q\n",
      "\n",
      "cQ = .5*Q\n",
      "cb = np.matrix(((0, 0.))).T\n",
      "cc = -1.\n",
      "def constraint(x):\n",
      "    return .5*x.T*cQ*x + x.T*cb + cc\n",
      "def constraint_jac(x):\n",
      "    return (cQ*x + cb).T\n",
      "def constraint_hess(x):\n",
      "    return Q\n",
      "\n",
      "tol = 1.e-2\n",
      "print(constraint_jac(np.matrix(([-1], [.1]))))\n",
      "\n",
      "multiplier0 = np.matrix(((0.)))\n",
      "print(\"multiplier0 = {}\".format(multiplier0))\n",
      "maxiter=200\n",
      "result = scipy.optimize.minimize(fun, x0=np.matrix(([-1], [.1])),\n",
      "       \t                         constraints={'type':'eq','fun':constraint},\n",
      "\t                             method=augmented_lagrangian, tol=tol,\n",
      "\t                             options={'multiplier0': multiplier0,\n",
      "                                          'store_iterates': 'iterate',\n",
      "                                          'maxiter':maxiter,\n",
      "                                          'outer_maxiter':maxiter})\n",
      "print(\"multiplier0 = {}\".format(multiplier0))\n",
      "print('success = {}'.format(result.success))\n",
      "if not result.success:\n",
      "    print(result.message)\n",
      "from PyPyContact.Tools.Optimisation import modified_cholesky, line_search\n",
      "\n",
      "\n",
      "multiplier0 = np.matrix(((0.)))\n",
      "result2 = scipy.optimize.minimize(fun, x0=np.array(([-1], [.1])), jac=jac,\n",
      "                                  hess=hess,\n",
      "       \t                          constraints={'type':'eq','fun':constraint},\n",
      "\t                              method=augmented_lagrangian, tol=tol,\n",
      "\t                              options={'multiplier0': multiplier0,\n",
      "                                           'store_iterates': 'iterate',\n",
      "                                           'min_method':newton_linesearch,\n",
      "                                           'maxiter':maxiter,\n",
      "                                           'outer_maxiter':maxiter,\n",
      "                                           'constraints_jac': constraint_jac,\n",
      "                                           'constraints_hess': constraint_hess})\n",
      "print(result2.success)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-2.   0.2]]\n",
        "multiplier0 = [[ 0.]]\n",
        "multiplier0 = [[-25.95639127]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "success = True\n",
        "iterations: 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "FailedIterate",
       "evalue": "evaluation of dual objective function failed with the following message: 'Line search did not converge. Are your jacobians correct? wolfe1 = False, wolfe2 = False, alpha = 0.0004224326612529694, nit = 40'. current tolerance is 1e-08 The full result is\n message: 'Line search did not converge. Are your jacobians correct? wolfe1 = False, wolfe2 = False, alpha = 0.0004224326612529694, nit = 40'\n       x: array([  1.00715259e+00,   6.50456781e-09])\n     jac: matrix([[ -1.29008093e-08],\n        [  6.45837364e-09]])\n success: False\n     nit: 59\n    hess: matrix([[  4.05541115e+03,   2.62043693e-05],\n        [ -6.01417741e+00,   4.00000000e+00]])\n     fun: matrix([[-0.10307763]])",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mFailedIterate\u001b[0m                             Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-0f6428a12552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m                                            \u001b[0;34m'outer_maxiter'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                                            \u001b[0;34m'constraints_jac'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconstraint_jac\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                                            'constraints_hess': constraint_hess})\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    428\u001b[0m         return method(fun, x0, args=args, jac=jac, hess=hess, hessp=hessp,\n\u001b[1;32m    429\u001b[0m                       \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                       callback=callback, **options)\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_neldermead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-3-770448cb9383>\u001b[0m in \u001b[0;36maugmented_lagrangian\u001b[0;34m(fun, x0, args, constraints, tol, update_tol0, multiplier0, penalty0, alpha, beta, tau, min_method, callback, bounds, jac, hess, constraints_jac, constraints_hess, hessp, store_iterates, **options)\u001b[0m\n\u001b[1;32m    275\u001b[0m                     (\"evaluation of dual objective function failed with the \"\n\u001b[1;32m    276\u001b[0m                      \u001b[0;34m\"following message: '{}'. current tolerance is {} The full result is\\n{}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                          iterate.message, current_tol, iterate))\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mconstraints_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mnorm_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstraints_eval\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mFailedIterate\u001b[0m: evaluation of dual objective function failed with the following message: 'Line search did not converge. Are your jacobians correct? wolfe1 = False, wolfe2 = False, alpha = 0.0004224326612529694, nit = 40'. current tolerance is 1e-08 The full result is\n message: 'Line search did not converge. Are your jacobians correct? wolfe1 = False, wolfe2 = False, alpha = 0.0004224326612529694, nit = 40'\n       x: array([  1.00715259e+00,   6.50456781e-09])\n     jac: matrix([[ -1.29008093e-08],\n        [  6.45837364e-09]])\n success: False\n     nit: 59\n    hess: matrix([[  4.05541115e+03,   2.62043693e-05],\n        [ -6.01417741e+00,   4.00000000e+00]])\n     fun: matrix([[-0.10307763]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "iterates = np.array([iterate.x for iterate in result.iterates])\n",
      "print(iterates)\n",
      "res = 51\n",
      "x, y = np.linspace(-1.1, 1.1, res), np.linspace(-1.1, 1.1, res)\n",
      "X, Y = np.meshgrid(x, y)\n",
      "XY = np.zeros((2, res, res))\n",
      "XY[0, ...] = X\n",
      "XY[1, ...] = Y\n",
      "Z = fun(XY)\n",
      "phi = np.linspace(0, 2*np.pi, 97)\n",
      "plt.contour(X, Y, Z)\n",
      "x, y = np.cos(phi), np.sin(phi)\n",
      "plt.plot(x, y, c='k', lw=2)\n",
      "plt.plot(iterates[:, 0], iterates[:, 1], c='r', ls='--', lw=2)\n",
      "iterates = np.array([iterate.x for iterate in result2.iterates])\n",
      "plt.plot(iterates[:, 0], iterates[:, 1], c='r', lw=2)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ -1.00000000e+00   1.00000000e-01]\n",
        " [ -8.57076097e-01   9.67215953e-02]\n",
        " [ -8.38563417e-01   1.04563485e-01]\n",
        " [ -9.79132964e-01   1.23481062e-01]\n",
        " [ -9.90841265e-01   1.25053285e-01]\n",
        " [  1.01214873e+00   7.65678540e-08]]\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7fa0e14ee438>]"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd801X3x99puhctlFlGBWQjICBTKEOQJYKsBxUn6CNO\nxL1Q4AFRAX8iQwEFBJQhyN7TAsoQZFNGoYwO6G6aJs33/P74toVOOjJL3rzuK2ly870nIfnce889\n91yNiODEiRMnTsoWLrY2wIkTJ06cmB+nuDtx4sRJGcQp7k6cOHFSBnGKuxMnTpyUQZzi7sSJEydl\nEKe4O3HixEkZxNXWBmSh0WicMZlOnDhxUgJERJP7MbsauYtIicpnn32GiGDU61n/6qt8W7s21w4d\nKvH1ilSiLyMf9kReaYGcO2zZtvIrpptI4rvIjfJI4hgkI6bYn5e1iklMXJKLrJM1TJFJzJD/Y6fs\nIFaKbrMti7U/L0cvjvB5pUoqR+Qwi2QBE+RzFstC/pVjpEu6/X5eSjqSMhuJqo7c6oMYVN0pCLsZ\nuZeWxCtXWD54ML5VqzLq8GE8AwIs05CiwMYfYOEnMOAtGPQOuLpZpq1820+C1OmQ+n/gNRgq/gva\nYOu1XwyiiOIYRznOv3jhRROa8BwvEkSQrU1zco/jjTcteJAWPIgePac5xT8cYS1/UI/6NOUB6lAX\nV3uSSI07+LwE3s+A7keI6ws+rxZY3Y4sLzlx58/z40MP0X7sWNq9/TYaTZ4ZinmIugTTXgB9Kny5\nC0IaW6ad/JB0SJ0BqVPAowcE/QWudazXfhFJIpFjHONfjqInnQdoxgieoRKVbW2aEyf54olnttCn\nkMJJTrCXPaxiJY1oTAtaUp3qaLCQrhQXjSf4vAbeL4ASB3yUbzWHFncR4c/Jk8nYtInBv/9OrU6d\nLNUQbJoHP38Ag96FgWNAq7VMW/m1rV8Fye+AayMovx3cmpTqkqGhoeaxLRMTJs5yhkMc5CqRNKIx\nfehHTWrhYl+evxJh7s+rrOPIn5cvvrShLW1oSwLxHOMYK1mGG260pBUP0BxvvM3aZok/L403aAu2\nRVOYz6ZI19do5gN9gBgRaVpAnf8DegE64FkR+SefOlIcWwwpKfzx3HMkRkYyZOVK/IMt5JpIiFFH\n6zevwTsLIaR0wlosjMcg6U1QYsF/Gng8Yr22i0AC8RziEP9wmEDK04rWNKIx7rjb2jQnTsyGgkIE\nERzhEOc4Sz3q8yCtCCHELgYvGo0GyWdB1Rzi/jCQAizMT9w1Gk1v4FUR6a3RaNoA34pI23zqFVnc\nEyIi+LV/f6q2akWfmTNx9fAo1XsokEObYepz0H0EPP0FuFlJtEwxkPwxpP8BvuPAeyRo7GOSZcLE\nOc5mj9Kb0ZxWtHa6XYqAQSA6A25mQIICCaY7bjPvpyqQpoBeIE1Ar2TeCigCAiiotyLqfQ3grslZ\n3DJvvV3AL5/ir4XyLlDRFSpqIcgVfGyvU3aPDh3/cpRDHMJEBg/RlhY8iCeeNrPJYuKeefEQYG0B\n4j4b2Ckiv2X+fQboLCLRueoVSdwv793LiiFD6PD++7R5/XXL+NcNevjpA9i7Qh2tN+ti/jbyQwzq\nQmnKZPAeAb6fgEugddq+C6mkcphDHOQv/ClHK1rTmCbOUTqq6EZnwBUjXMmAywaIzICoDPXxrJKi\n3BbTgKzicvu2nBZ8XcBLA55ZtxrwcgEPDWg1anibJrO4aNRbAYyidh53lnRRO4rkO0qSKfNWgTgT\nxJrUzibWpF4rSAuVXCHYFaq7qSX7vivUcFPtudcRhCtc4W8OEM45mtCUNrSlMlWsbktB4m6N4WAw\nEHnH31eB6kB0/tUL5tiiRWx5+20GLFpE3Z49zWVfTq6eg/8NgWp1YdYx8CtvmXZyY/gTEl8CbU0I\nCgPX+tZp9y7cJJZ9hHGC4zSkEcN5iqpUs7VZpUZRFHQ6HUajEYPBgMFgyL6f+zFFUXBzcydB6841\ncSMSdy7jRoS4E6lx5zpu+Lu7U8vPixAvV2q6QYgbtPOCyq6ZRQuBWlWQ7RER0AnEZkCMCa4Z4WqG\nensyHa4a4VoGRBqhghbud1dL3Ttu67mrndK9gAYNtTL/JZPEIQ6xkJ8JoiLtaE896tvcZWONkfta\nYLKIhGX+vQ14V0SO5KpX4MhdRNj9xRcc+/lnhq9fT8VGjUptc77sXAKz34AR46H3S2CpqJs7UeIh\n+X3QrwP/b8HzCeu0WwiCEEEE+/iTq0TSmod4iLb44mtTuwpCURRiYmK4evUqV69eJSoqivj4+Bwl\nISEhx9+JiYmFxgiXFF9fXwIDA3OUgICAHH9XqlSJ6tWrU716dapWrYqbmxVDaUuJSVShP2+A8MyS\ndf+SEWq5QVMPaOIJTTzUUscdXO20UzMnJkyc5AT7+BMDBjryMA/Q3OLhlLYcuV8Datzxd/XMx/Iw\nbty47PuhoaGEhoZiMhhYO3IksadO8cL+/fhWscC0x5AOc96Eo9vhf1uhTnPzt5EbEdD/BkljwHMA\nVDwFLuUs325hJiGc5Qx72E0aOtrTkSEMww3bio9eryc8PJzw8HAiIyOzRTyrXLt2DaPRWOzrent7\n4+rujsbNHcXNnQytGwZXd8TVDW8Pd3zc3fD3cMdXq8Etw4jJmP8IP+tWp9ORkpJCSkoKkZGRdzcA\n9YdZpUoVatSokS34WaVOnTrUr1+fcuVs+724E60GarmrpVuu5wwC59LheDqcSIeFCertjQx4wBNa\neUIrL2jpCQ09yp7ga9HyAM1oygNc4iJ72cMOttOODrSiNR6YZ21w165d7Nq16671rDFyv3NBtS0w\nvagLqvqEBH4bOBAPf38GLl6Mu49PqW3NQ/RlmDAIKtWEMT+Bj7/528hNRgQk/RdM16DcHHBvZ/k2\nC0FB4SQn2MMuNLjQmVAa0siq00oRITY2ljNnzuQoZ8+e5dKlS3cdZVeoUCFbIKtWrUr58uXzjJjd\n/AOJ9ArkrEcA/7qX46DRFUWgjRe09oLmntDME2q4lmzypCgKycnJ+c4U7izR0dHZHdONGzfu+t6q\nVq1K/fr1adCgQY5So0YNXFzs3w+SbIJ/9HBYD4fS4JBedfc081Q/9w7e0MELqjnOBKbIXOcae9nD\nJS7yEG1oQzt8MK+OWTJaZinQGQhC9aN/BupQT0TmZNaZATwKpALP5XbJZNbJIe7J16/zS8+ehHTp\nQs9p03CxRFz5ka3w1dPqLtOBYyzvDhEFdLMg+TPwHQs+b4PGdt9oEyaOcZS97MYbHzoTyv3Us/hm\nDZPJxJkzZzh06BCHDx/m8OHDnD59mvj4+Hzra7VaateuTb169ahVq1b2yDZLzIODg/Hy8srzungT\n7E6F3Tq1nEuHFp6qmD/kpd7WdLOtF8xoNHLjxo0cM5HIyEgiIyMJDw/n3Llz6PX6fF/r5eVF/fr1\nadGiBa1ataJly5Y0a9YMT0/bRW4UlcRMwT+QBmE62JcG5VxUoe/oDZ28oYG7zT2UZuMWN/mTvZzi\nJA/Sko50MpvIWzRaxhzcKe5xFy6w6JFHaDlqFB3ee8/8ETEi8PtUWPkNvL8UHuhs3uvnhykSEp4H\nSYGAn226YKqgcILj7GAb5QgglC6EcJ9FRF1RFM6dO8ehQ4eyyz///INOp8tTt1y5cjRo0CDPKLVO\nnTq4u989KidNgV2psC0VdupUX3A7L+jiA529oaWXGh7oSCiKwpUrV3LMZLLuR0VF5anv6upKkyZN\naNmyJa1ataJVq1Y0bdoUD0uFC5sJReCMQRX6vTrYo1PdPD18oIcvdPdRo3gcnUQS2ctujvMvD9GW\nDnQsdRilw4h7zIkT/PLoo3T65BNavfSS+RtKT4NvR8GVU/DpKtUdY0lEIO0XSH4bfN4En3dtFrMu\nCOGcYytbcMONR+jBfdQ2axsGg4GDBw9m+wUPHDhASkpKnnq1atXKFp+WLVvStGlTKleuXKyOXERd\nyNuUAhtTICxNda308FEFvbUDinlxSExM5OTJkxw5ciS74zx9+jSKouSo5+bmRvPmzQkNDaVLly50\n7NgRPz8/G1lddC4YYEsKbEmFnalQ2/222Hf0duz/23ji2MkOwjlHezrShrYlDit2CHGPPHCAX/v3\np+e0aTT9z3/M38it6zCuPwTfD2/OBU/zbiPOgykWkl6GjLMQsAjcWli2vUK4wmW2sgUdqXSnBw1o\naJaRutFo5NChQ+zcuZNdu3YRFhaWZ1Reo0aNHCPJli1bEhRUsuRhBlFdLWuSYUOKurmnl69auvuo\nseL3MqmpqRw9ejTHTOns2bM5/PparZaWLVvSpUsXQkND6dChg92LvVHg7zRV7DelwDkD9PSFx/zU\n//tAB/1/jyWGHWznCpfpTCgtaY2W4r0ZhxD3KRUr0v+nn6jXp4/5Gwg/Ap/3h77/haEfWN6Zp98I\niS+A15PgN15N9mMDYohmG1u4wQ260I3mtCjVQqmIcPr0adatW8f27dsJCwsjNTU1R52GDRtmRzt1\n6tSJKqWMcEpV1B/0qmTYkAz1POBxP+jtq4bdlRW/rKVISkpi//792bOpgwcPYjKZsp/XarW0atWK\nrl270rt3b9q1a4fWWrmTSsgNI6xPUTv5XTo1EucxP+jvB/c54L6661xjC5tJJJEe9CzW4MshxP3S\nrl2EdLaA//uv9TD1WXh1Fjw8yPzXvxMxQvKHkPabOlr3sII/Px/SSGMH2zjBcTrSiYdoU+KQRqPR\nyN69e1m7di1r1qzh4sWLOZ5v0KBBtpiHhoZSuXLpUxHoFFibDMuSYGuquvg5IPPHG1wGoyqsSXJy\nMmFhYezatYudO3dy+PDhHGIfFBRE79696devHz179rT7Ub1OUddZ1iSrpbY7DPeHIeWgigP56QXh\nPOFsZhPeeNObvlQpwo5XhxB3i9iy8Uc19/qnq6FhnghM82KKhPihasqAgIXgUsGy7eWDgsIRDrOD\nbTSkEd14pERZ7OLj49m4cSNr165l48aNJCYmZj9XoUIF+vTpw6OPPkpoaChVq1Y1j+2iRrUsSoRV\nSWpEy1B/VdArONCP1NFISkoiLCyMLVu25Om83d3dCQ0NpV+/fvTr149atWrZ0NK7kyGwPRWWJKpC\n39oLhpdTBwaO4rIzYeIwh9jJdhrRmK50LzSy5t4TdxFY9Jm663TCRtXPbkn0GyDxefB5C3zeAY31\n448jiWQ9a9GipQ99qUbxMmUmJCSwYsUKli5dyu7du3OM5ho2bEi/fv147LHHaNu2rVmn7afSYVEC\nLE6E8lp4OkAdeVV1jtCtTpbbbe3ataxdu5Z9+/bl8Nc/8MADDBs2jOHDh9u90KcpsC5FFfodqfCo\nLzwfoK7NaB3AladDx052cIJ/6UJXWvFQvi7Ve0vcM4wwfaQaEfPFOgioZJ7r5ocYIfkTSFsMgUvB\nvaPl2iqAFFLYymbOE84j9KQZzYvsr9Pr9WzYsIFffvmF9evXYzAYANUP26lTp+wRW926dc1qc7IJ\nfk2CH+PVnCVPloOny0FT+w/RvqeIjY1lw4YNrF27ls2bN+eIfHr44Yd58sknGTx4MOXLWykHUwmJ\nN8GviTAvAWIy4NkAtdR2AP98NNGsYw1GjPTjMYKpnuP5e0fc9ToYP1A9+u6DX8HTArtaszBFQ8Jg\nNWl+uUWgrWi5tvJBEP7hMFvZQjOaE0rXIsXMKorC7t27Wbx4MStWrMh2uWg0Grp27cqTTz7J448/\nTmCg+TNSHtXDzDhYngShPjAqQA1tc4SR1L1Oeno6W7ZsYfHixaxZs4a0tDRADbXs1asXTz31FH37\n9s13Q5k9cUwP8zNnig94wKhAGOhv36GVgnCUf9jKZhrRmO70yP6t3xvirkuGT/tA5RAYMx+0FnTU\nGv+B+MfB61nw/czqbph44vmDVehJ43EGUoW7+70jIiL44YcfWLRoEVevXs1+vEWLFjz55JMMGzaM\nYAscepKuqGI+M15NOjUqEF4IcLpdHJnk5GRWrVrF4sWL2bZtW3ZsvZ+fH4MHD+bll1+mdevWNray\ncNIV+CMZZsfDWQOMDlS/m0F2vL6jQ8cWNnGB8/TlMerToEBxt/kp5FlFNaUUJMeLvNFGZPooEZOp\ndNe6G7oVIlFBIrpllm0nH0xikgOyXybJBNkjuyVDMgqvbzLJhg0bpG/fvqLRaITMcx7uu+8++eij\nj+TUqVMWs/VWhsj/YkWqnhXpFiGyKlHEqFisOSc24saNGzJ9+nRp3bp19vcLkFatWsn8+fMlNTXV\n1ibelWNpIs9fEwk4LTLymsiJNFtbVDgX5LxMk69lh2yTTO3Mq6n5PWiLUipxT4gVeaWFyMzXRRQL\nqoeiiCR9IRJVQ8Rw2HLtFMBNiZW58oP8ILMlRmIKrRsbGytTpkyR2rVrZ//Y3N3d5emnn5a9e/eK\nYsHP6UK6yGs3RAJPi4y4KnLUzn8oTszH2bNn5Z133pHy5ctnf+8CAwNlzJgxcu7cOVubd1eijSJf\nxIhUOSvySITIhiTLSkppSJd0iZe4Mizut26IjGosMu99Cwt7qkjcEJHYNiIZ1y3XTj6YxCT7JUwm\nyQTZJ2FikoJnJgcOHJARI0aIh4dH9o8rJCREJk+eLDExhXcIpeVAqsigKyIVzoi8HyVy1WDR5pzY\nMTqdThYsWCBt2rTJMZrv0aOHrF69WjIyCp9x2hq9SWRBvMgD59WyJMF+Z51lU9zjokRebCDyy+eW\nFfaMKJHY1iLxT4ko1h2GJkmS/CzzZY7MkpsSm28dRVFk48aN8vDDD2f/iDQajfTu3VvWrVtn8R/S\nXzqRnhEitc6JfHtTJNnCXjEnjsWhQ4fk+eefF09Pz+zvZ926dWXu3LmSnp5ua/MKRVFE1ieJdLwo\ncn+4yMJ4+xP5sifu8TEiIxupwm5JjOEi0bVFkj61+vzsnJyTKTJJtsmWfH3rJpNJVqxYIQ8++GD2\njyYgIEDeeecdOX/+vMXtO6IT6XtZpPpZkVm3RNLt7EvvxL64deuWTJ06NYersHr16jJ9+nRJSUmx\ntXmFoigiO1JEOl0SqRuujurtReQLEnfHjJZJjof3usBDfeHZCZYzyngE4vqC3zjwHmW5dnKRQQbb\n2cpxjvMEg/JkbjQajSxZsoTJkydz5swZACpXrsyYMWN4+eWX8fe37IEjx/UwLhb2p8EHQTAy4N45\nO9McZGRAXCLcjIebCZm3mSUxBVLTIFWXeZtZdHowmUBR1P15ity+D+DhDp4eavFwy7x1B19vCPRX\nS4D/7fuB/lAlCKpUVOtZ9/1nsGzZMv73v/9x8uRJQE158NZbb/HKK68QEBBgXYOKya5U+CxWPQB9\nYiV4ws+2+Y3KTiikLhk+fAQatodR31juU03fDgn/Af/Z4DXQMm3kwy1uspzf8Mef/gzMse04PT2d\nefPmMWXKFC5fvgxAzZo1effdd3n++ectHl98yQAfxai7/d4Jgv8GgrdT1PMQnwjhl+HydYiMgis3\n1NvIKLhyXRX0QH8ICoSgAPW2YnmoUA7K+YGPV2bxvn3f2xNcM0+IctGAi8vt+wKkG9SiT8+8zbyf\nooP4JNWm+KTbJS4Rom9B9E21zWqVoFpF9Ta4MtSuDnVrQp2aaidgiZ+ZoiisW7eOiRMn8vfffwPg\n7+/P6NGjeeutt6hY0br7RoqDiJrz6P0Y9azSyZWhqwW31BRG2RB3gx4+7gXB9eD12ZYT9rQVkPQK\nBCy3auKvk5xgLX/QhW48RJvsXaaKorB06VI++uijbFGvX78+H3zwAcOHD7f4AcsJJpgQCz8lwhvl\nYUwF8L3HRV0EIq7ByfNw+gKcuQRnI+DsJVVc768FtapBzapQo4paalZTb6sEgb0kXVQUiI2D6zFw\nIxaux0LkDbh4Fc5fgQuR6syhdnWoUwMa1IZm9dVSL0TtcEqLiLBjxw4mTpzIzp07ATVe/v333+fN\nN9/E29vCqblLgSLqHo6PY+E+N/i6snperDVxfHE3mWDSUHDRwntLLPfr0C2E5Peg/EZws8JB2ajJ\nvnawnWMcZRj/ybG9eMeOHbzzzjscOaKeTNi4cWPGjRvHgAEDLJ6W1STqdu1PY6CfH4yv5FhZ9syF\nosDFSDh8Cg6fhCOn1OLlCU3rQYP7oGFtVfjqhVhupGsrklLgQqbQn7oAx87CsTNqR9CoDjRvoIp9\n66bQomHp3Dz79+/niy++YNOmTQBUq1aN8ePH88wzz9h1GmKjwA/x8EWsmnp4YiXrnRzl2OIuAjNf\nU3PFjN8I7hY6Mix1DqSMh/Jbwa2hZdrIhR49K1hGOukM5T/44gvA8ePHee+999i4cSOgfsknTJjA\niBEjrPIl350Kb0SBvxa+rQwt7HtHuVnRpcFf/8KfR2DvYfj7OJTzhQcbQcvG8GBD9X4V+/UaWIXk\nVDh+ThX7o6fVz+ncZXigHrRrDu2aqbfVS5DOf/v27bz77rvZg5omTZrw5Zdf0qtXL/Mfu2lGEkww\nPhYWJsK4ivByoOVTazj2DtWlE0X+20wkJaFYq8jFIuX/RKJrqdExViJWYuRbmSpr5Y/saJjIyEh5\n7rnnsneT+vn5ycSJE622y++GUeQ/kSI1z4n8lmC/GzjMSXyiyKqtIm9/KfLQEBHvB0Xa/Ufkna9E\n1uwQibllawsdh+QUkZ1/ifxvjki/V0SC2otU7yLy9HsiP/0ucqUYW0RMJpMsXrxYatWqlR1d06VL\nFzl48KDl3oCZOJ6mRta0uCCy38I/XRw2FHLzfJERISI3LbhxKOX/RKJDRIyXLNdGLs7IaZksE+WQ\n/C0iIgaDQSZPnixeXl4CiKurq7z22msW33iURYYi8v0tkaDMDUgpZThW3WgUCTsi8tl3qoj7thTp\n8aLIhFkiu/4W0Tl31JoNRRE5e0lk9q8ig99Uxb5uT5GXPhP5bYPIzfi7X0Ov18s333wjgYGB2SL/\n4osvyq1b9t3rKorILwlq+o0XronEGi3TjmOK+z/bRYZVFrlyxnyfRG5S51hd2PdJmEyRSXJZLqt/\n79snTZs2zf7iDho0SMLDrTeDOK0XaX9RpMNF+8+pUVISkkR+WSPyn7Ei5duKNHtc5N2vRbbtE0nT\n29q6eweTSeToaZGpP4v0eVnEv7VI6DMi3y4UuXyt8NfGxcXJ2LFjxc3NTQCpWLGiLFq0yKKpNMxB\nQobIGzdEKp8RWRRv/tmw44n7tfMiQyuJHN1h3k/iTnSLRaKCRYyW3/AjoqYR2CQb5FuZJvESJ/Hx\n8fLyyy9nu2Bq164tmzdvtootIiIGRU3sVeGMyIxbIib7/o0Um/hEkQWrVfeAf2uRvv8V+XG5yNUo\nW1vmJAtdmsjqbSLPfCBSoZ3Ig0+IjJ8lcuJcwSJ4+vRp6dSpU/ZgqFu3bg6Rt+agTqTpeZH+V0Si\nzDiKdyxxT0lUd5+u+d58n0Bu0laLRFUWMZywXBt3YBSjLJff5AeZLSlKivz6669SuXLlbBfMhx9+\nKDqdziq2iKg+wQcvqMmRLtn3DvBiEZ+o+nazRoX9R4ss+kMduTuxb4xGkR0HRF6boPrpG/VVffcR\nV/PWVRRF5s+fn52gzMPDQ8aPHy96vX1Pw/QmkQ+j1VH8skTzXNNxxN1kEvm0n8i3L1luNU+/VSSq\noki6dRZm9KKXn2W+LJaFEn45XB599NHsUUeHDh3kxAnrdDAi6uh86k3Vt/5DXNlYMDUaRdbvEhny\nliroj78qsnitSGKyrS1zUlJMJpG9h0ReHqeO6Ds+qfrtb+Xy0cfExMiIESOyf08NGzaUsLAw2xhd\nDA6kitQLFxkWqabGLg2OI+4/fywytpOIwULDyfT9ai729D2WuX4uUiRFZskM+UNWyZJfl0i5cuWy\nc8D88MMPYrJ07vk7uGYQ6XpJ9a+fLwOj9XOXVL95lYdF2gwVmbk074/fieOTni7yx/bbnXf/0SIb\n9+Q8tmH79u1y//33CyAuLi7y6aefitFooRVMM5FqEnnzhki1syKbSjEQcQxxP7BW5KkaIvHRJX+n\nhWEMF4mqIpK2zjLXz0WiJMr/yXRZlfh7jtHFY489JlFR1nX8bkxWc1R/HqNGxjgqRqPIis3qIlyl\njiJjp4icvmBrq5xYi8Rkdd2k+QCR+x8Vmb7wtsstLS1N3nvvvew1rLZt28qFC/b/5diRoibfeydK\nXQcrLo4h7kMriZy00JTKdEskup5IyizLXD8X8RIv0+Rr+X7f99lZ8Ly8vGT27NlWXd03KOqXpvpZ\nkV32nXivUBKSRL6eL1Krm0j74SK/blBHdE7uTRRF5M/DIsPeFgloo7pvTmSuqe7cuVOqV68ugPj6\n+sqCBQvsPqIm1ijS67LIw5fUGXZxcAxx/31a8d5VUVHSRW6GiiSOscz1cxEvcfKVcbK88PkLotVq\nBZAWLVrI6dOnrdJ+FpEGkXYXRXpfFomx7xlqgZy7pC6wBbYRGT5W5K9jtrbIib1xPUZk3AyRqp1E\nuj4rsmmvyM2bt2TQoEHZs+WhQ4dKXFycrU0tFJMiMj5GjYvfUYyBmGOIuyV6V0URiX9W5NZjIorl\nT3+Jlzj59OrH8kCHB7IPzXj33XetfijBzhT1S/K/WMcMcTxwVOSxzB2OH0wVibxha4uc2Dvp6SIL\n/xBp8pjqtlm8VpF5834SHx8fAaRGjRqyb98+W5t5V7ZmulAnxhTtt+sY4m4Jkr8RiWkhYrK8TyJJ\nEuX1sFelQpUKAkhwcLBs377d4u3mZnacSKUzIlscMFrk8Ek1jLFGF5EZi0VSrRcd6qSMoCgi63aJ\ndHhSpF4vka9mh0vr1g9lnyM8b948W5t4V7Jm3QOv3P1ks3tT3PXb1AVUY4T5r52LVEmV4XOHiaub\na3YOjNjY/I/FsxRGRT2YukG4SLiD+aOPnxMZ+LpItc4i3/0ioncw+53YH4qi7kB++CmROo8YpEff\n17LdNK+99poYDPZ9yK/eJPLcNfUM14hCfg/3nrgbL6mblPQW3OGaSbIhWUJf7Zz9xXn99det/sWJ\nzxDpEaGWePs+ezgH5y6pKQEqd1QXTJ0jdSfmRlFEtu8XaT1EpOaDc8XV1c1mA7DiomTuS6l2Vt3h\nmh/3lrjpwXOAAAAgAElEQVQrqSIxzUVSLLRAewfXY69Lg9D6Np3ynU9XR+uvXrefcx3vxs14kdcn\nqhtUJswSSXLgSB4njoGiiCzbKBL8UJi4e6m7w0NCQuTo0aO2Nu2urEpUNx7+kc9O63tL3OOfFol/\nyuLbL48dPyYVQ4IEkCpVqthkseawTl04nWHfCfKyMRpVt0vFDiKvfOFMp+vE+qSni3zxbaS4+rZS\nQ5S9vWXlypW2Nuuu/J35W5+Z6zdz74h76iKR6Abq6N2ChIWFiW+ArwDSqnUruXo1nwQYFubPVJGK\nZ0RWmilHhaUJO6JGMYQ+czsm2YkTWxEVo5PGLZ/KjmqbNWuOrU26KxfSReqcU0Mms8au94a4Gy+o\nqQUM/5T+WoWwadMm8fT2FED6Pd7Pqgm/stiSrE7TSrNt2VrExok896FIcKjIknVlI5+Nk7KBoijy\nxpjx2etlb4yZbGuT7sp1g5pd8q0baqhk2Rd3xSAS28bifvZly5Zl55Me9uwwm+SvWJ2kjtj32Lmf\nWlFElq5XF0vfnORM5OXEfvnuuxnZAt+my7uSkmrfI5C4DDVU8u0b94K4J30scutREcVyibh++OEH\ncXFxEUCee+s5qyb9ymJxgpou9JCdR5Vci1Y3ITXup25IcuLE3lm8eLG4uqqhzH7BI2XTHvsOO0sx\nqQftlG1xTz+ghj1mWG4b45dffpnds780YZRNclUszjyyy95PS1q5RU3q9cn/OePVnTgW69atE09P\n1eXqVXGwvPRput0fu1h2xV1JE4lpKKL7rWSvLwITJ07MFvYXZjwvilhf2FclqiP243b8RUtKUX3r\ndXqI7HeO1p04KLt37xZ/f391l3mdx6RJP6Ocss5hbSWiIHF3wdFJ/hxcG4HnYItcftasWXz00Udo\nNBpGLHqKmaNnoUFjkbYKYnsKjLoB62tCE0+rNl1kDp+E5gNBq4Wjv0PbZra2yImTktGpUyd27txJ\nYGAg1y6swTfxeR5+WmH+SlDHoQ5CfopfnAI8CpwBwoH38nk+FEgE/sksHxdwneJ3Wel/iURVEsmw\nTG70xYsXZ+eGHjCnv8SK9Xez/a1TF0/tNV2voqg5YCp2UDeIOHFSVti/f3920rHhT78mjfoqMnys\n/QUGYAm3DKAFzgMhgBtwFGgoecV9TRGuVbx3pKSLxDQW0S0p2SdyF9auXZudrrfP5N5yQo5bpJ3C\nOKdXXTFr7PT8T12amoa3+QCR8AhbW+PEifnZunWruLu7CyAffPCpjPpUPSTEnvZpFCTurqUc+D8E\nnBeRCACNRvMr0B84naue+f0Yqd+CtiZ4DjP7pXfv3s3gwYMxmUwMeO9xnnlvBI1pYvZ2CuNWBvSJ\nhPGVoJ+fVZsuEteiof+rUD8E9i0BLzt1Fzk6JpNCQoKehAQ9RqOCyaRgMgmKItn3NRrw9XXPUdzc\ntLY2vUzQvXt3li5dyuDBg5k06QumTQukw8tvEvos/Pg5PN7d1hYWTGnFPRiIvOPvq0CbXHUEaK/R\naI4B14CxInKqVK2arkPKlxB0ADTm7TeOHDlCv3790Ov1DH1pCK0nteJRepu1jbuRrsDAq/C4H4wM\ntGrTReKvY/DEm/DqcHjvRbP/F9wTGI0mrlxJJCIigUuXEoiIUEt0dCpxcWnEx6cRF5dGSooBf38P\nAgI8cXfX4uKiQat1QavVZN8XEVJTjSQnp5OSYiAlxYBW64KvrzsVKngRHOxPcLBfZlHvV6/uT716\nFQgM9LL1R2H3DBw4kHnz5vHcc8/x1ltv8dNPAWyY/SyPvwYXImHMs/b5GyituBdleeEIUENEdBqN\nphewGqiXX8Vx48Zl3w8NDSU0NDT/Kya9C96jwLVuMc0tnKioKPr160dycjJPDH2CFt83Y6BmEB54\nmLWdwhCBkTcgSAuTK1mt2SKzeC28ORnmT4B+XWxtjf2TkaFw9uxNjh2L5tixKI4di+bUqViio1Op\nWtWX++4LJCQkgJCQcjzySG2qVvUjMNCT8uW9KF/eC39/D7Ta4sU9iAjp6SaSk9O5eVPHtWvJXLuW\nxLVryZw9e5MdOy5x9WoSZ8/ewtfXnYYNg2jUqGJ2ady4IhUr+ljoE3FMnn32WRISEnjrrbcYOXIk\nO3bUYf+Sh+n7Cpy/At99BK6lVdMismvXLnbt2nXXehopxfKvRqNpC4wTkUcz//4AUETky0Jecwlo\nKSJxuR6XItli+BPih0PF0+Bivi+gwWCga9euhIWF0bFjR17ePooK7hWsPmqfEAt/JMPuEPC2o1gm\nEZj0A/ywHNbNgib329oi++Tq1SS2b7/I3r1X+OefKE6fjqV6dX+aNatCs2aVadasMo0bV6JGDX+b\nu05EhKtXkzh9+ianTsVmlxMnYqhQwZu2bavTrl11OnWqRZMmlXBxscPhqZUZM2YM06ZNo1KlShw+\nfBj/gOoMGaP6nZdNAz8b9IkajQYRyfOfU1pxdwXOAt2A68DfwH9E5PQddSoDMSIiGo3mIWCZiITk\nc627i7sI3GoDPm+C1/AS250fr7zyCrNmzSI4OJilh5dwpPJhXuFV3HAzazuFsSUFnrsOh+6DqtZr\n9q6IwPtTYeNe2PQDVLPDGYWtSEjQs2tXBNu2XWTbtovcvKmja9f7CA0N4cEHq9KkSSV8fd1tbWax\nUBTh7Nmb7N9/lX37Itm79wqxsal07FiTbt3uo1+/+tSubYf+QiuQkZFBz5492bFjB61bt2bPnj24\nunry3y/g37OwcQ6UD7CuTRYR98wL9wKmo0bOzBORSRqN5iUAEZmj0WhGA/8FMgAdMEZEDuRznbuL\ne9oKSPkfBB0CjfmGtXPnzmXkyJF4eHiwfe92DrQOYwCDqE1ts7VxN24YoeUlWBwMXexoRqwo8OYk\n2HcUNv8IFaz8xbVHrlxJZOXKU6xYcZrjx6Np164G3bvfR/futWnWrEqZHOFGRaWwZ89ltmy5wNq1\n56hUyYfHHqvHY4/Vp3Xr4DL5ngvi5s2btGrVisuXL/Pcc88xb948QMO7X8OmP2HLXKha0Xr2WEzc\nzcVdxV2MENsYyn0PHo+Yrd0DBw7QuXNnDAYDP/30E5WfrUgaaQxkkNnauBsmgUcuQ2cf+MyKX4q7\nYTLBy5/DyfOwYTYE+NvaIttx6VI8K1aogn7hQhyPP96AJ55oSNeu9+HhYSVnq51gMin8/fc11qw5\ny5o154iLS6Nfv3oMHdqYLl3uuyeE/ujRo7Rv3560tDRmzJjB6NGjEYGJc2DBatg+H2pWs44tBYm7\nzdMOZBXuFueeMlPkZvfC6xSTGzduSNWqVQWQV199Va7JVZksEyVFrLtj6PMYkdBLIhl2lIjOaBR5\n6l0193qynW6gsjSxsakydeo+adlyjlSsOEVGjVojW7acF4PBvhNKWZtz527KV1+FSfPms6VGjany\n4Yfb5MwZ+z6+zhwsWbJEAHF1dZU9e/ZkPz5tgUjtHiKXr1nHDhw6t4yiE4mqKmI4VPpPIuuSiiJ9\n+/YVQDp16iR6g15my/dyRA6brY2i8GeqSJWzItfs6KzejAz1XNMeL96bZ5oeOnRNnn76dylXbpI8\n9dTvsm3bBTEarZ8B1BE5dixK3n57s1Sp8rW0bz9PFi06Jmlp1k+LbS3efvttAaRmzZqSmHj71Jxp\nC9QcSzdiLG+DY4t7yrcit/qX/lO4g/nz5wsgAQEBcvXqVTkq/8hsmSkmsd6POMUkUjdc5Hc7OklJ\nUUReHS/SeYTYfTY8c2I0mmTZshPSocM8qVFjqkyevFdu3boHezYzYTSa5PffT0mPHoukUqWvZPz4\n3RIfX/a+UAaDQVq2bKkmFXzhhRzPjZsh0mKg5c8HdlxxV/QiUcFmHbVHRESIn5+fALJo0SIxiEG+\nkSlySS6ZrY2i8PoNkSetfzpfoXw1T6TJYyLxdtThWBK93ijff/+31Kw5TTp0mCfLlp1wjtLNzOnT\nsfLMM6ukfPkv5f33t0pUlJ0lZyklJ06cEA8PDwFk/fr12Y8rishLn4l0f149t9VSOK64p8wSudXL\nPJ+CiJhMJunatauaDGzAAFEURf6UvbJYFpqtjaKwM0Wk2lmRW3bkvl26XqR6F5Er121tieVJT8+Q\nWbMOSo0aU6VXr1/kwIFIW5tU5rl0KV5eeWWdBAZOltde2yCXLyfY2iSz8dVXXwkgVatWlVu3bp9g\nnZEh8virqpvTUmf7OKa4KwaR6Foi6fvM9kHMmKEepxUUFCTR0dGiE51MlokSLdFma+NuJJtE7jsn\nstaOEoLtOahmdjx2xtaWWJaMDJPMnXtYatacJj17LpL9+52ibm2uX0+SsWM3S2DgZBk5co1ERzv+\nin1GRoZ06NBBzSA5fHiO53RpIh2fFLHU8ayOKe6630RudjLbhxAeHi7e3t4CyMqVK0VEZIdsk99l\nhdnaKArvR9mXOybyhkiVh0U2/2lrSyzL9u0XpWnTmdKp008SFnbF1ubc89y6pZMxYzZJxYpTZPbs\ng2Iy2VG4WAm4U1+WL1+e47m4BJF6vUTmrzR/u44p7jcfFtEtz/t4CenTp0+OnjVN0mSSTJCbVszT\nfj5dpPwZ+4mO0aeLPDREZPKPtrbEcty8mSrPPLNKatWaJitXnrLJEYlOCubYsShp336etGnzoxw5\n4tg+we+//149wSk4WFJScs5ITp0XCWovcvikedt0PHE3HFUXUhXzqOCWLVvUg2/9/CQ6WnXB7JZd\nslwsdzxffgy4IjLRCuFRRWXUpyIDX1cXf8oaiqLI0qXHpUqVr+WNNzZKcrLzQFd7xWRSZO7cw1Kp\n0lfyxhsbJTFRb2uTSoTJZMqOnhk3blye53/doIZIJpjRJet44h7/okjSBLO8+YyMDGnSpIkAMnmy\n6vhKl3Sr+9p3pIiEnBNJs5NgjLkrRBr0sb+TZczB5csJ0qfPYmnSZKZzsdSBiI1NleefXy3Bwd/I\n6tWnbW1OidizZ48A4u3tLVev5vW/jh5v3gGVY4m7KUHkRjmzHZ83Z84cASQkJETS0tRY2/0SJktl\nsVmuXxQURaTFBZFldhJimDVFPH3B1paYn8WL/5WgoCnyxRe7JD3djsKRnBSZPXsipHbtb2X06PUO\n+X/4xBNPCCDPPPNMnuf06SKtBovMWmqethxL3FN/FLk1wCxvPDExUSpVqiSA/Pab6oIxiUmmyTdy\nWSLM0kZR+D1RFXd7cH9kZIi0HSYy00xfLnshPT1DRo5cI/XqfefwvlsnIvHxadKv3xJp336eXLtm\nR6FlReD8+fPi5uYmgBw6lHePzukL6uDqohkmlQWJux1lDL8D3QLwftYsl5o0aRIxMTG0b9+ewYMH\nA3CecDzxoAY1zdLG3VAEPouFLyrax4kt//cLeLjDS0NsbYn5iI5OoWvXBcTEpHLo0EhatKhqa5Oc\nlJKAAE9Wrx5G7951ad36R/bsuWxrk4pMnTp1eP311wE1B7yqwbdpUBvefR5e+ETNvGoR8lN8WxSy\nRu7GcJGoSmZZSI2OjhZPT08B5MCBA9mPL5Cf5B85UurrF5VliSKt7WTUHh4hUqFd2TrQ+vDh61Kz\n5jT59NMdDh9O5yR/Nm0Kl0qVvpJp0/Y7TLRTfHy8VKhQQQDZuHFjnuezZtDfLyldOziMWybpE5GE\nN0r3bjP55JNPBJB+/fplPxYrMTJZJopRrJPMyKSINDovssEOZpWKomZ5/OYnW1tiPpYvPylBQVNk\n+XIzx5c5sTsuXoyTFi1my7BhK0Svd4xkZJMmTRJAunXrlu/zZy6W3j3jGOKuKCLR9UTS/y75O80k\nNTVVypcvL0COdJybZKNslry9qKVYlyTyoJ2M2n/bINJ8gDpiKAv8+ONhqVr1a/nnnxu2NsWJldDp\nDDJw4G/Sp89ihxD4+Ph48fX1FUAOH84/4+zE2SIDXit5GwWJu3353DNOAXpwa1XqS/3888/ExcXR\npk0bOnbsCICCwr8cpQUPlvr6RWVaHLxV3va+dn06vDcVpr0PWtse3WkWpk7dz4QJe9i9+1maN69i\na3OcWAkvLzd+/fUJPDxcGTx4OQaDydYmFUpAQAAjR44E4Jtvvsm3zphn4egZ2L7fvG3bl7jrV4Ln\nwFIroclkYurUqQCMHTsWTeb1LnIRP/yoiHUOAT2uh1PpMKScVZorlGkLoHkDCH3I1paUnq+/3sfs\n2YfYs+c57r+/gq3NcWJl3Ny0/PrrE7i6ujBkiP0L/BtvvIFWq+W3337j8uW8i8KeHvD1OzBminr6\nmbmwT3EvJatXr+bChQvUrl2bAQMGZD/+L0dpRotSX7+oTI+D0YHgbuNRe1QsfPMzfDXWtnaYg5kz\nDzJz5kF27HiGmjXtoNd0YhNUgVePwhw6dIVdC3ytWrUYOnQoJpOJb7/9Nt86A7qDrzf8stZ87dqX\nuCtR4Na+1JfJGrWPGTMGbaYPIoMMznCaJjQt9fWLQrwJVibBS3ZwSPzEOTCiP9StZWtLSsfq1WeY\nNOlPtm8fQfXq9/CBrk4AcHfXsmzZYDIyFF58cU2ecEN7YuxYdWT1448/kpSUlOd5jQamvA2fzQCj\n0Txt2pe4e/QATekcwufPn2ffvn34+vry7LPPZj9+iUtUpBJ++JXSyKKxPAke8YEgG5+dHBULi9fB\ney/Y1o7ScvJkDCNHrmXVqqHcd58d9JhO7AJ3d9VFc/JkLF9+GWZrcwqkRYsWdOzYkZSUFP744498\n63R4EEKCYdkm87RpX+Lu3qPUl1i6dCkAAwYMwMfHJ/vxs5ymAQ1Lff2isjgRnrQDr8HUBfBUP6gc\nZGtLSk5cXBr9+//K1Kk9aNXKSkfKO3EYfHzcWbNmGN9/f5BVq07b2pwCefLJJwFYsmRJgXXeewGm\nzAdzTELsS9w9upfq5SKS/cENHz789uMIZzlDAxqU6vpF5YoRTqRDL1+rNFcgickwdwWMfc62dpSG\njAyFYcNW0L9/fZ5+upmtzXFipwQH+7Nq1VBGjVrHmTM3bW1OvgwaNAhXV1e2bt1KbGxsvnUefVgV\n9s1/lr49+xJ3bem2jB87dowzZ84QFBREt27dsh+P4gZaXAmiYmktLBK/JsITfuBh40/3x+XQ62Go\n6cCD3Y8/3gHAl18+YmNLnNg7rVpV43//68qgQcvQ6zNsbU4egoKC6NGjByaTieXLl+dbR6NR0xJM\nmV/69uxL3EtJlktmyJAhuLm5ZT9+gQvUpS4arBO28kcyDLLxep8IzF0Jo4ffva69EhZ2hYULj7Fk\niRr25sTJ3XjxxQepV68CkybttbUp+ZLlUcjSqvwY2gtOnofwiNK1VWZ+MYqiZH9gd7pkACK4RAj3\nWcWOWxmqS6azt1WaK5C//1UTErVrbls7Skp6egbPP7+GGTN6ExRk4w/TicOg0Wj47rtezJx5yC7d\nM/3798fLy4s///wz35h3ADc3eLIv/Ly6dG2VGXE/evQokZGR1KhRg3bt2mU/rqBwhctWE/dNqRDq\nbXuXzII/1PBHW++MLSlff72PBg2CGDjQeovgTsoGwcH+fPJJJ15+eZ3dhUf6+vrSr18/ANasWVNg\nvecGqL/h0mxqKjPivmvXLgC6d++Oi8vttxXFDfzwwxfrrG5uSIY+1om2LJB0gxpO9XQ/29pRUiIi\nEpg27QDffvuorU1x4qCMHt2alBQDCxYcs7UpeXjkEXX9aPfu3QXWaVoPqgTBtlKkJChz4h4aGprj\n8StcoRYhVrFBBLamwqM2jpLZEgaN60KtYNvaUVI++WQnr732ECEhAbY2xYmDotW6MGdOXz74YDtp\naWbaFWQmsjRq9+7dhc4sRjwGS9aXvJ0yIe4mk4m9e9UFlM6dO+d47gbXqYZ1wkXOG8BTAzXd7l7X\nkmzYA/1CbWtDSYmISGDDhnDefLOtrU1x4uC0bFmNtm2r8+OPR2xtSg7q1KlDtWrVuHnzJqdOnSqw\n3mNdYePekrtmyoS4Hz9+nISEBGrVqkWtWjn32F/nOlWtJO770qC9jdf+RFRx793JtnaUlG++2cfI\nkQ9SrpynrU1xUgb46KOHmTIljPR0+wmN1Gg02YPQwlwzIcFQqTwcPFGydsqEuBfkkjFiJI5bVKKy\nVezYnwbtvazSVIGcOq8uojasY1s7SkJMTCqLFx/njTfa2NoUJ2WEVq2q0bRpZbvzvWdpVZZ2FUSf\nzrC+YP0vlDIh7nv27KEn8N/0dJgzB375BVatImnzMqpf1+KGdfwk+3TQzsYj94171Y1Ljhgl8/33\nfzN4cCOqVrXxirSTMsXHHz/M5Ml/YjJZ6rDS4nPnyL0wv3vfUoi7xl5ChTQajZTUlrp16/LRhQsU\nuMv+/vuhcuWc5c8/4a+/wNsbfHzU4u0NH38MffrkvcaGDXD27O36WbcPPABVq2IU8D8DCfVtGwY5\n8HUY3BP+k89bsGdEhDp1/o+VK4c4D7d2YnaaN5/N9OmPEhoaYmtTAPX7HhgYSGJiItHR0VSqlP8Z\nEwYDBLaD6D3g65NvFTQaDSKSZzhn45yFpcdgMBAREcEW4OnRo3E1GCA1FXQ64lIjKb/1MISHq+VO\nqleHpCS13Em/ftC2LVSqpHYCJhPUrw8HD0J+W4YXLoSnn+a8Aaq73SHszz8PK1bk7Ah8fGDcOOjZ\nM+911qyB8+fz1m/WDKoU/aShgyfU1KGOxpEjN9BqXZynKjmxCEOHNmb58pN2I+4ajYZ69epx8OBB\nwsPDCxR3d3doej8cPgWdWxevDccW9+RkXCtWxJC5nOwye7bqj3BxAVdXjB3qktirPeXEX11pNJkg\nLQ3CwkCngxo11G2cJhO4usLLL8OUKbA/n+DSDh3gv/9Vu9K0NPX1qalQsyYAp9Ohofsd9ZOSIDlZ\nLeR6PD9++SX/zmPpUhg2LO/jTz8Nf/yRY9ZhcPehZeoE6tTslrf+6tVw8WLOzsPbG1q0UDsxG7Ns\n2UmGDGmUfWqWEyfmZMCAhnTrtpDvvuuNi4t9fMeyxP3cuXN06NChwHqtmsDhk/eauOv1uKSn3/77\nzpghg4HKW/8t+LVxcWq5k48/Lrh+WJhaQD2E1NMTvLzgqafAy4sObl608vAEfy/1OQ8PeOIJtdPQ\natUOR6uFf/6BK1fU13p53b5OzZowaJCaqd9oVDsRgwH8/NROxNMz5+GniYl5Og93oHm35Pz97QsW\nqAKfmxUrVDtzM2QIbNyY02Xl4wOTJ0OuhWsAVq6Ey5fzurlatoSKhSdsExGWLTvF6tVDC63nxElJ\nadAgCH9/Dw4evEabNtVtbQ4A999/PwDnzp0rtF7LRrC1BJuZHFvcg4L4dsIEpn/8MSOHDePDN95Q\nhTA1FdLSWB64lV5pXfDVu6qj7bQ0SEmBc+fU++npoNerxWiE8uXV+2lpt2/vvJ91m5Fxu51MLDb2\n3bPn9n03t9udgZeXupbg7q4WV1eu3nJlyPV58NSKnB1HVsfQqZPaASrK7U7k2jXYuzdvZ3PrlvpZ\npaTktOeO95yD+fPVdYncrFmjurpyM3AgbNsG3t4Y3b3YEJVOg5eWwjffqLOk3CxbBlev5l3zaNUK\nghw4Wb0Tq9G37/1s2XLBbsS9Xr16wN3FvVkDmLaw+Nd3bHHXaDh15QoRgG+7dqqvPBNBOMVJHmcI\nmDtaJiMjj/j/90IaT3voae9SQIdwt8eK8nyWIOd29WSS/ZUtznkFb7xx9zru7upMxN0dRo+Gd9/N\n2XF4eUFMDDRsqLq/RG67u7ZsgUuX8nY2ERHZMw93UI9R+esGxMaqna67e86Qn7lzYevWvLZt3AiP\n5pOmoG9f2L077xrG9Ok5vifZLF0K16/nrd+6NVRwHsJdFmjZshrLlxe8acjaFFXcQ6rB5evFv75j\niztw8eJFQI2YuZN00tFioTBIV1fw9VVLJmFaeCkYsNTeGxFV2AvpBD6enMYTHdNoUbuYHUthnY1e\nf9tFBOqIvjjMmFG8+lkHmms0OTsEg0EV2ay8QRqN+plMnw6//Za3szl1Kv+ZR9Z6Su7OZuZMNYIq\nN9u2Qbd81jB69FCvlbszmDFDnU3kZvFiiIrKu+bRpo06Y3RicVq0qMKHH263tRnZZLllLly4UGi9\nwHLqWCkhCQKKkUrc4cU9MTERgAq5Rlc6UvGmgNghC3AjA6pa8tPUaG67YMrlf37f8q/hyScBc25g\nElFH0uaYfRTwWMSZKCr7u+BFRs5Zik6nlsLYvLl472fMmMKf12hur5G4uMCLL4K/f1631ZEj+Xce\nCxaokVW5O5tJk+Dkyfzt7979dqeVRZcu6nVyr3nMmQPN88njvGCBOuvJXb9dOwhw5ugBqFu3PLGx\nOhIS9AQE2H4HtJ+fH1qtlrS0NIxGY44zKO5Eo4GaVeHKjXtM3JMzXRS+vjmzdaWSig/W2VFkFEgw\nQVDpzvYuFSLq1K2muUPENRpVoDw9IdD8B1OLCE38JnH1zBi87vzBmUy3Zw6lnX0U5zGTSXW7ZRER\nUbw3VNyZSlZYrLt7zg4hOlq1Kfcax4cfQnBw3s5m5kyIjMx7/dmz1ZlE7s6mTx/499/bnUFWhzBv\nHjRpkvc6P/2kBiDkXvNo3z7/wYaI3e2k02pdaNq0Ev/+G02nTrXu/gILo9Fo8PX1JTExkZSUFAIL\n+X1lifsD9Yt+/VKLu0ajeRSYDmiBuSLyZT51/g/oBeiAZ0Xkn9K2m0WWuPv55dzVaMCIG+75vcTs\n6BTwdgGtDb/LBqP6e/JxsHMtkpMNaDSavCMprfa26FiTjAyzzUiKdZ0s11dBobJZbNxYvPfz8suF\nP5+78+jfX+3Ec7uttm2D+Pi8rx87FurVy9vZjB6tdoze3urfvr7q/+VPP0HTpnmFf+5cSEjI6+bq\n0EGdOeWmhJ1HcLA/0dEpd69oJfz8/Iok7oHl1DORi0OpxF2j0WiBGUB34BpwUKPRrBGR03fU6Q3U\nFZH7NRpNG2AWYLaUfymZ0+Lc4m4iA1crTUz0omaDtCWpOvC2cV6bkhAfn0ZgoO2nyNm4uqrhp35W\nTEKEiHMAACAASURBVIEgogq7JWck+T12ZxhxFplrWEXm668Lf16vz/l3s2aqCyr3TCIyMn97+veH\natXydjbTp6tuqKywYy8vtVMYP16NIsvd2SxcCDod/a9fIGjDKdCcVus//HD+/9dWmnlkeRySCwiS\nyMLbE3T6QqvkobTq9xBwXkQiADQaza9Af3LGazwGLAAQkb80Gk2ARqOpLCLRpWwbESnQLZNhRXFP\nU8DLxll6UtPAxyHFXU9goAMabk40GlWgPDwKXE+xCIpyez3F3DMSnU69TU3N+VxWxFdR1lNA3ahX\nGFkL/VkMHlxo9acA9gE/Zz7QoIG6JnFniLGnJ6xfr9ru5nZ7rcvTE0aNUne35+5s1q9XZ31+furM\np1o1debRuXP+s8/MziNrUJqSe+0mF7YQ92DgTkffVaBNEepUB0ot7mlpaSiKgoeHR57FCBOme2rk\nrtM7qrjb2cj9XsLF5bagWZOs9ZTSzEjS0tRQ2tRUdVE7c28LWu3t/Su5O5v8cledOVO4rVluuiw+\n+aR477VJE7XTvrNtETWay2AgTAQFcGnfHr77Tt0Fnw/eXqBLy/epAimt+hU101du6cv3dePGjcu+\nHxoamieFb24yMhe+XF3zvg1B0ORp1jKYxPbpNTMyQGtrI0qAwWDC3d2GK9FOrI8t1lNEICODbyfv\nJP5GAuPea1N4Z5KamnMXeFZH4uubNyQ5LU1dX0hLyxsqfKLwZOzZQ1KTSW2vAFy1YMxc59+1a9dd\nUwVD6cX9GlDjjr9roI7MC6tTPfOxPNwp7kXBJ/PLodPpUBQlx9mpWrSYKMXpssXA0wXSbZxc09ur\n+NM2eyAgwJOEBAc03IljodGAmxsxei1e1apALQtFyyQlqVFIHh63273ThixEQK/nid69MSYn8/n7\n79NixIgCL6vTQ2DmunLuge/nn3+e72tKK+6HgPs1Gk0IcB0YCvwnV501wKvArxqNpi2QYA5/O4BW\nq8Xb2xudTodOp8vhd9eiJQPrnL7iqVFdM7bEx0HFPTDQi/h4BzTciUOSkKC37HkB/v7QsWORq4eH\nhHD8+HHGDxum+ukLQJdW/ICJUom7iGRoNJpXgc2ooZDzROS0RqN5KfP5OSKyQaPR9NZoNOeBVCg4\n7XpJ8PX1RafTkZycnEPcXXGzmrh7udhe3L091UVVRyMw0JP4eAc03IlDkpCQ/v/tnXd4FOX2xz+T\nHmoICR0NSq8iHUNREKWKWLD3K5arcq8F60X9iaBgF7tXEUERRaSICNxQBelFIISeEJJACOl99/v7\nY5IIIY1ka9jP88wzs7uTec9OZr/zznnPe45LTGAqpLRov+JkZpu/8fOhyiOOkpYAS4q992mx1/+s\najulUbt2bU6cOHHOaLMPPg7tuWc6uchLjUDIzjFdd95u5MKuVy+Q1NQc8vOt+Pi44aCBB7fi1KlM\nlxrALy3arzjpmecfMOH2v6bCO17xONFAAsmiAqFWNiDQME9kmmNc/CXi5QUN60PcSefZUBl8fLy4\n5JJ67N3rZoZ7cEt27z5J27auk0W0oj334yegScn1PErF7cW98I6XWmxmX01qkkEp6WltjGGYeWXi\nnFxgPawpHClxqNq16d69CZs3VyLtnQcP50FiYiapqTm0aGH7NBqVIS8vj+zsbLy8vAgIKPtpojKp\nRdxe3Js2bQpAdHT0We8HEkg22VhxjL/EFcT94ibuKe7dujVmy5Y4Z5vhoZqzfXs8l13WyGUqMRVq\nVtOmTcusQJaTC0kp0Ljsmjfn4PbiXlpOZG+8CSCATAe5Zhr7Ol/cK5v32dl4eu4eHMG2bXF07eo6\nNXoLNatQw0ojJg6aNjz/sbRqK+4AtalNGuUkYrIRF/nAkTyHNFUqrcNgT9mpoV2Sbt2asHdvIqdO\nOeZG7OHCJCLiCH36uEYVJqi4uEcehpYXnf/xq7W4BxNMEknnvG8P2vmbRbKdSfeOsKnsCXEuSY0a\nvgwZcinz55czFdyDh0qSmprD2rXRDB3aytmmFFFRcd+y26yjer64vbgXVjPZv38/KpY7oh71HSbu\n7V1A3NtdYo6qJzvmYcWm3HRTe374wXVKoHmoXvz663769buYOnX8nW1KEYXiXqhhpbF5N3TrcP7H\nd3txr1evHiEhIWRmZnL8+Nl+2/oEk8R5loWrJO38YW9uybmJHIWPD3RtB5vdsPc+fHgrNmw4RmKi\nxzXjwfbMnbuHMWPaOtuMs6hIz12CTbugZ6fzP77biztA27bmP23nzp1nvR9MfU45SNyDvKG2Fxx1\nst+9ZyfYsLP8/VyNmjX9uPbalsyZ44Z3Jg8uzcmTGaxYcYgxY9o525QikpOTiY6OxtfXl7CwsFL3\nO1yQqat5JSqsVQtx79u3LwCrV68+6/2GNCKBeFTh5JVVo2cg/OnkmfRX94Xf1znXhsry+OM9efvt\nDeTnO3m6r4dqxbvvbuCWWzq6VN2ANWvWANCrV69Sa6cCLFkD14RXrm5ItRD3AQMGALBq1aqz3q9F\nLXzxJZlkh9jRNxD+cLK4D+gB2yPhdOnZQ12WK664iCZNavPjjx7fuwfbcPp0Fp98soVnn614Mi9H\nUKhVhdpVGotXwfD+lWujWoh7eHg4Xl5ebNq0iYxiNSEb0Zg4HBND3bcG/OFkl3FgAPTvDsv+cK4d\nleXZZ69gypS15wyOe/BQGT74YCOjRrUhLCzI2aacRWE+9rJqVmRkwtqtMOSKyrVRLcS9Tp06XH75\n5eTn5/PHH2erWmOacNxB4t4tAPbkQIaTvQrD+sPi1eXv54oMG9YKi0X89tsBZ5viwc1JS8vhgw82\n8txzrtVrT0lJYdu2bfj4+NCnT59S9/vfn2aUTFAJ9cErQrUQdyjdNdOMZsQQXdKf2JxAL+gWCGuc\n3HsfdSUsWmlmiXQ3DMPglVcG8vTTy8jLc2ImNg9uz8SJKxkxojWtW9d3tilnsW7dOqxWKz169Cgq\nOFQS3/8KYwZXvp1qI+6FjzcRERFnvX8xYcRyzGHpf4fVgsVlFzK3O80amSGRC/7nXDsqy/XXt6VZ\nszp88MFGZ5viwU3ZujWOWbN2MXXq1c425RwKNaosl0xyqvn0fduIyrdTbcS9f//++Pv7s379emJj\n/86eFUAAIYQQe071P/swrBYsTnduvDvA3aNhRjmF410VwzD44IOhvP76GmJi3HBk2INTsVisjBu3\niClTBhESUsPZ5pyFJObNmwfAkCFDSt1vzhIY3AfqV2GooNqIe506dRg+fDiS+OGHH876LIwWHOGw\nQ+zo5A95gn25DmmuVMYMhj+2Q7ybpklv1ao+TzzRiwcfXOQZXPVwXnz00SZq1PDlnnsuc7Yp57Bx\n40YOHTpEkyZN6NevX6n7ffUz3Ht91dqqNuIOcOutZvnW2bNnn/V+GC04xCGH2GAYMLw2LHCya6Zm\nDbh+EHw937l2VIVnnw0nISGdDz/0uGc8VIz9+0/x6qur+fTTEWWm0XUWhdo0duxYvEtJ87hzH8TE\nwzWVjJIpxLXEXVUbARw+fDi1a9dm8+bN7N+/v+j9S7iU48SShWOC0MfWgdku4E14/A74cDbkOvkp\norL4+nozd+5NvPbaGlauPOJsczy4OJmZedx441xefXWgS1VbKsRisTBnzhwAbrvttlL3m/pfeOx2\nM51IVXAtcc+tWnB2YGAg119vPst89913Re/74cfFhHGA/aX9qU0ZUAMSLfBXtkOaK5XL2kH7S2HW\nIufaURUuvTSYWbPGcOutP3H0qGMmo3lwP6xWce+9v9C5c0Meeqi7s80pkYiICBISEmjZsiXdunUr\ncZ+jsfDranhobNXbcy1xz/m9yocovCPOnj37LF9tW9qyD8eklPUy4Na6MMsFeu/PPwiTPzcLZ7sr\ngwdfwjPP9GX06DlkZjo5eY8Hl+SVV1YSHZ3C55+PdEl3DPzd4bzttttKtfHtGXDfmMrHtp+Ji4n7\n0iofYtCgQTRo0IB9+/axdu3aovdb05b9RGHBMSp3R4G4W5w8FjigB4QGww+/OdeOqjJ+fG86dWrA\nvff+gtXqGWD18DezZu1kxowdzJ8/loCAKvoy7ERycnJRoEfh2GBxTiXDNwtg/F22adO1xN0SDZaY\nKh3Cx8eHcePGATBt2rSi9+tQhxBCOYhjZj52CTDrqi5Od0hzpWIY8Oo/4cX3zVqM7ophGHz66Qji\n4tJ49NHFnggaDwDMnbubJ5/8nUWLbqNhw1rONqdUPv30U9LT0xk0aFBRFtvivP4p3DLULKlnEyS5\nxAJIp++R0t9TVUlISJC/v78ARUZGFr3/p9brB31f5eNXlNnJ0sDDDmuuTEY+Ir35hbOtqDopKdnq\n2fNzjR+/RFar1dnmeHAiP/64Ww0bTtX27XHONqVMcnJy1LhxYwFasmRJifscipGCe0txJ87/+KaM\nn6uprtVzDxgD2T9V+TANGjTg7rvvBuCtt94qer8DndhPFNk4ZqTzxjqwPxe2O3lgFWDa0/DGl3DC\nMent7UadOv789tvtrFsXw8MPL8Zi8aQHvhCZN28vjz76K7/9dgddurhO0euSmD17NnFxcXTs2JFr\nrrmmxH0mvAVP3AmNQm3YcEmK74wFkKxZUlxdKT/+/G9fxYiMjJRhGPL391d8/N/Hm6WZ2qJNVT5+\nRZl8Urr7mMOaK5MnXpceetnZVtiG1NRsDRjwlW677Sfl5uY72xwPDmTevD1q2HCqtm497mxTysVq\ntapDhw4C9PXXX5e4z8qN0sWDpMysyrWBW/TcjQDwH2aT3nubNm0YNWoUOTk5fPjhh0Xvd+VytrCl\nysevKA/WMyc0xbhAkMd/HoZ5y92zDF9xatf2Z8mS20lNzWHYsNkkJTk5kb4HuyOJ997bwMMPL+bX\nX2+na9dKlCdyML/99hu7d++mSZMmJQ6k5uTCo/8HU58y03XbEtcSd4DAOyFrhk0O9dRTTwEwffp0\nkpPNGOnWtCGVVI4TW9af2oxgb1PgX090SHNl2xIEbz0N973ovhObziQw0Jeffx5L584N6NXrC/bs\ncdNcCx7KJSMjl9tum8eMGTtYv/5+Lr/c9YVdEq+//joATzzxBH5+fufs8+pH0OpiuLFkb03VDXCF\nxTRFkjVPim8s5e6p3DPKGVitVg0YMECAnnzyyaL3V2uVftLcKh+/opzMk4IjpSM5DmuyVKxWafhD\n0ivTnW2Jbfn6620KDX1TCxZElr+zB7ciKipRHTt+pHvuma/MzFxnm1NhfvrpJwEKCQlRcnLyOZ9v\n3Ck1CK/cIOqZUIpbxumiXmRIobhLUsrTUsqEqn3jArZs2SLDMOTr66sDBw5IkjKUoUl6VWlKs0kb\nFeH5BOkfsQ5rrkxi4qSQvtKuKGdbYlvWr49R06Zv6eWXI5Sfb3G2OR5swPz5exUa+qY+/niTW0VH\nZWdn69JLLxWg6dPP7UllZUvtR0jfLa56W+4l7rl/SfFNzF68Dbj77rsFaMyYMUXvzdc8RWiFTY5f\nEU7lS/UjpQMu0HuXpM9+kLrfJOW4iD22IjY2VVde+bX69/9KBw8mOdscD5UkJydfzz67TM2ava31\n62Ocbc55M23aNAFq166d8vLO1bFnpkljHjefpKuKe4m7JJ3sI2X9XPVvLunYsWOqUaOGAK1atUqS\ndEIJmqJJypHj1O21E9IN0Q5rrkysVjP2/dH/c7Yltic/36KpU9epfv03NG3aOuXleXrx7sQff0Sr\nc+ePNWzYLMXHO+7p2lacPHlSdevWFaBff/31nM9/XSU1HSglJNqmPfcT98xZUuIg23x7SS+//LIA\ndevWTRaL+WP/XrO1Vmts1kZ5ZFqksCgpIt1hTZZJcqrU6lppxnxnW2If9u8/pauumqHu3T9z+Yku\nHqRTpzL1j38sUOPG0zR79k63csOcyaOPPipAQ4YMOec7RB+XGoZLq20Yje1+4m7NkeIbSrm7bXIC\n0tPT1bRpUwH64gtzqmacjutNTVauHDdI80OK1OWAlO8i1+2uKNP/vtU2p9nlsFqt+vLLrQoNfVPP\nPbdcGRnuMyB3oWC1WvXVV9vUsOFU/fOfi5WcXMmAbxdg586d8vb2lpeXl3bt2nXWZzk5Up9bpTds\nPFPc/cRdklJfkpIfsdlJ+PbbbwWobt26io42/SOz9I026A+btVEeVqvU77D0iQu5g7//VQobLCWe\ndrYl9iMuLk1jx85V8+Zva+bMHbJYXOTueoHz118J6tfvv+re/TNt3uwiEQeVJDc3V127dhWgRx45\nV7cefkUa9YhksbGX0D3FPT9WiqsnWU7a5CRYrVaNGjVKgK6++mpZrVYdU4ymaopDfe/bs6TQSCnW\nhTqRT70pDbhLyq5mA6zFWbv2qHr1+lydOn2kH3/c7RF5J7F370ndfffPCgl5U9Onb6wW0U0TJ04U\noLCwMKWmpp712bvfSO2GSyl2GEJwT3GXpNP/kFJfsM1ZkBQXF6f69esL0McffyzJ9L2v0kqbtVER\nXkqQRhy1zWi5LcjPN0fvb33K9j0LV8NqtWrhwn26/PJP1aXLx5o3b4/b+nfdja1bj+vGG39QaOib\nevXVlUpKynS2STZh8+bN8vb2FqCVK8/Wku8WS82ulI7YKQ2J+4p73kEpLliy2M5n8MMPPwhQzZo1\ndeDAASUqUZP1mtLluJHOHKvpe//ahVwhmVlS39ukCW852xLHYLVa9csvkera9RN16fKxZszYruxs\n24TfejibtWuPaujQb9WkyVt6660/lJZWfR4Rs7Ky1L59ewEaP378WZ8tWyeFXiHt3Ge/9t1X3CXp\n9N1S6itVPglncssttwhQeHi48vPztVC/aLEW2rSN8ih0z8S4kHvmZJLUeqj0wbfOtsRxWK1WLVq0\nT1df/Y0aNZqmiRMjFBfnfiF4rkZubr7mzt2t/v2/UosW7+qTTzYpK6v63TyfeuopAWrdurUyM/9+\nEtm62xT2VXbOU+je4p63T4oPkSznTuGtLImJiWrUqJEATZ48WWlK02S9phOq4lzg8+TVE9KQI5Ir\nuX4PxZhxuNU1RLIsdu8+oXHjFiooaIruuGOeVq8+4nHZnCeRkSf1/PPL1bjxNPXv/5Vmz95Zbeca\nREREyDAMeXl5af369UXvRx2WmgyQfvrd/ja4t7hLBb33F6t0EoqzaNEiAfLy8tLvv/+uP7ROX+pz\nWeW4H3OuVepzSHrTNmPGNmPPAVPgP3dcCh6X4tSpTL311h9q1+5DXXLJe5owYZk2bYr1CH0pJCZm\naPr0jerV63M1ajRNTz65VH/9leBss+zK0aNHFRoaKkDPP/980ftRh00f+xc/OsYO9xf3/KOm7z3f\ntjmcX3zxRQEKDg7WgUMH9LE+1FZtsWkb5XE0V2oQKf2R4dBmyyXqsHTRVReWi6Y4VqtVW7Yc13PP\nLVfLlu8rLOxdPfXUUm3YEHPBC/3Bg0l65531Gjjwa9Wu/brGjp2rX3+Nqra99DPJzMxUt27dBGjw\n4MFFKQZ27zc7RZ/94DhbbC7uQDCwDIgCfgeCStnvCLAT2AZsLON45X+LlCel5IdscDr+xmKxaPjw\n4QLUuXNn7U+P0hRNcujgqiT9kipdFGXmoHElDh+TLhlSPUr0VRWr1art2+P04osr1KbNB2re/G09\n9NBC/fjjbp06VT2iPsrCYrFqw4YYPf/8cnXoMF0NGkzV/ff/ogULIi+oyWFWq1V33XWXALVo0UKJ\niWYegU27zNmnM39xrD2libthfnb+GIbxJpAo6U3DMCYA9SQ9W8J+h4FukpLKOZ7KtcV6Ck60gZA/\nwKd1pewuieTkZHr27Mn+/fsZO3Ysd313BzlGDtdzg83aqAj/iodDuTC/uVnY2lWITYBB98Gtw+A/\nj7iWbc5CEnv2nGTp0oMsX36ItWujadMmhMGDWzB48CX06dOcGjV8nW1mlcjNtbB9ezyrVx9l9eqj\nrF0bTaNGtbjuujaMGtWGXr2a4eV14V0M77//Pk888QQ1atRg/fr1dO7cmdWb4cbx8PkrcN0gx9pj\nGAaSzvlHVEXcI4EBkhIMw2gErJR0TlnvAnHvLqnM6p0VEneA9Dchdy0EL6iU3aWxd+9eevXqRVpa\nGq+/+Tp+T/swiutohe1uIuWRK+h3GEbUhpdsWUvRBiQkwpB/QL9u8N5z4O3tbItci9xcCxs2HGP5\n8kMsX36I7dvjufTSYLp0aUiXLg257LJGdOnSiAYNajrb1BJJT88lMjKRPXtOsnNnAhs2HGP79ngu\nuaQe/ftfTP/+F9Ov30U0blzb2aY6lZUrVzJ48GAsFgtz5szh5ptvZs4SeGwSfDcVBvVxvE32EPfT\nkuoVbBtAUuHrYvsdAlIAC/CppM9LOV7FxF05cLIT1HkPAoZWyvbS+OWXXxg9ejReXl58NG86adel\n8AiPUYMaNm2nLOLyoPcRmNIAbq3rsGYrREoa3PAE+PvB7KlQ98L+nZdJdnY+e/acZMeOeLZvj2fH\njgR27EggIMCHjh0b0KJFEGFhQUXrsLAgGjWqhWGnxyJJnDqVRWxsKrGxaRw7lsq+fYns3WsK+okT\nGbRpE0L79qF06BBKr15N6dGjKXXq+NvFHndk3759hIeHk5iYyIQJE5g8eQqTP4NP5sDCj6DLOV1b\nx1ApcTcMYxlQUmnxF4AZZ4q5YRhJkoJLOEZjSXGGYYRi+ugfk7SmhP00ceLEotcDBw5k4MCBJRuW\n/SukjofQXWDY9uJ79dVXmThxIv7+/kxc8h9aXnkpNzHWpm2Ux65sGHQUfm4OVzjuvlIh8vJg/BSI\n+BMWTIeWFzvbIvdBEjExqezZc5IjR5I5fPg0R46kFKyTSUvLpWHDmtSrF0hwsLnUqxdAcHAgQUEB\n+Pl54+Vl4O1t4O3tVbQtmWXo0tJySU8/ezl5MpPY2FSOH0+jRg1fmjatQ5MmtWnatDZt2tSnfftQ\n2rcPJSwsCG9v16u66SpER0cTHh5OTEwMQ4cO5aefFvLoa95sj4RFH0OTBo6zZeXKlaxcubLo9Suv\nvGIXt8xASfGGYTQGIkpyyxT7m4lAuqS3SvisYj33QpJGgV8fqPXceVpeNpJ47LHHmD59OrVq1eIf\nK+7nvp7305FONm2nPH5Lh3tiYV0LuPTc0otO55PvYeJ0mPUGDO7rbGuqBxkZuZw4kUFSUhanT2cX\nrLOKXufnW7FYrFgswmpV0bZhQK1afkVL7dr+Rdv16wcWCbq7jwE4ixMnTtCvXz+ioqK44oormDl7\nKfe+VJM6tWD2m1DLyZ620nruVYmWeROYULD9LDClhH1qALULtmsC64AhpRzv/IaI8w5KcfWlvEPn\n93cVwGKx6PbbbxegoOAg/euvx5Ui202gqijTT0lt9ps1WF2RlRulRv2kt75ynRw5HjzYkuTk5KJM\nj126dNHS1ad10VXSC++a+ZhcAewUCrmcYqGQQBNgccH2JcD2guUv4Lkyjnf+3yrtTSnxSslq+7ja\n3NxcjRw50ixw26S+Xj80Sfly/H/z2Xip+0Ep1UUupOIcPib1uFka/U8pyfH3Pw8e7EZGRobCw8MF\nqFWrVnp+WrwahEvzlzvbsrMpTdwr7ZaxNeftlgGQBU5dAYH3QM2HbG5TVlYWQ4cOZdWqVTS4JJS3\n1kzjjiZ32bydspDgoTjYnwu/XgQBLugWzc2Fp6fBwpXw7RvQt6uzLfLgoWrk5uYyevRolixZQuPG\nTWnZfx1Wn4v5bio0b+xs687G5tEytqZS4g6QtxeS+kP9TeATZnO7UlNTueqqq9iyZQshLUP4dtlM\nrgm71ubtlIVFcFssZFvhx+bg66KhxfOXw0OvwIM3w0sPga/HxevBDcnMzOSGG27gt99+o25QCH4t\nVzPuznZMfAR8fJxt3blUX3EHSH8DcpZB8DK7zLBJTEzkmmuuYevWrdRpUpvFyxYT3r6fzdspi1zB\nmBio4QWzm4KPiwp83Em47wU4lWL24luHOdsiDx4qTnJyMiNGjGDdunUE1gyhVpvf+e7Drk6JX68o\npYm7Cz7kV4KaT4IyIPMDuxw+JCSEiIgI+vfvT+rxNK7pdy1rNp0TzWlX/Az4sRmkWWDsMcixOrT5\nCtM4FH79FO6+DvreBlO/hPx8Z1vlwUP5JCQkMHDgQNatW4dPQHMG3rSGPctdW9jL6g9Xj547QP5B\nONUbgleAb2fbGXYGWVlZ3HzzzSxatAj/Wv4sWrCIwVcOtktbpZFjNV00GVaY19zsybsqh2LgH/+B\n1Az472vQyXGTfT14OC+OHDnCVYOu5vChA/jUaM2n/13GfWMvcrZZZTI9CSJz4MMmNg6FtPVCZaJl\nipPxjXSivWS1X3rF3Nxc3Xb7bQLk6++reT/Ps1tbpZFnle48JoUfkpJdNIqmEKvVTBsc0lf69xT7\n1JD04KEq/PXXbtWr31SAQpt01aFDrp2q2Go160C03C8dzik9WsaF+32VIPAO8LkMUp+yWxO+vr7M\n/GYmD/3zIfJy8rjxhhv58MMPC29QDsHHgK+bQKcAcybrKRd2exgGPHAj7F4Ap1Oh3QiYvajsx0kP\nHhzFjFkRdO3Wj9OnYunarT/790TQooUDp5ueJ1bBvxPgx1RYEwZhZU1wLEnxnbFgi567ZFZrSmgh\nZdq3yoTVatUzE58RIED333+/srOz7drmuTZIE+Kl9gekaDfJuLpuq3TZ9VL/O6Utu51tjYcLlROn\nrBow4n2BWdR62LARZ5XIc0VyCp7Y+x6STp/xxI7bF+s4H3I3m2X5cv+y3TFL4cPZH8gnwEeA+vTp\no7i4OLu3WZxpiVLTfdKfrn1tFpGXJ33yvTm79a5npWjb1l/x4KFUMjKlVz7Iln/ofUUdswkTJijf\nVaablkJSvjTwsDQ6WsooNmfzwhJ3ScqYISW0lCxJtj1uCSzY/IvqNqsrQE2bNtXGjRvt3mZxfkmV\nQiKl79xolmhKmvTc21K9XtLjk6Q4x5av9XABkZdnjv006nNc9Rv3EaCAgADNnj3b2aaVy6Ec+zD9\nRwAAIABJREFUqe1+6V9xUn4JaT4uPHGXpOTHpVNDJav978rr4tcqLPxiAfL399fMmTPt3mZxdmRJ\nF0dJ/0lwrYLb5RF3QnridVPkn54qnbT//djDBUJenlkZqc0wqeuwjQptYA6cNm/eXFu2OLacZmVY\nnS412ie9f6r0fS5McbfmSokDpJTnbH/sEtiSs1m9HuxZ9Lj32GOPKSsryyFtFxKfZxbcvjFaSnez\nUpYxcdJDL0vBvaUX35NOnXa2RR7cldxcacZ8qdW1UvjtVo1/5hP5+/sLUHh4uBISXD8i5tMks7by\n0nIizC5McZek/AQp4WIpwzE96c3apDEfXy8fH9MP37FjR+3cudMhbReSZZHuOiZ1OiDtz3Fo0zbh\nUIx03wumyD/xunTgqLMt8uAupGdI730jXTxIuvIead6SExo1alRRh2vcuHHKyXHtH0WGRbrnmBko\nEVWBGA33EPfDuyp/Rsoid5cUHyrlrLbP8YuxSRv1xKbHdEmrS4rcNO+9956sDsyLa7WaKYNDI6Wf\nUxzWrE2JPi5NeEuq30e67lEzxbAntbCHkog+Lj3/jhR6hTTmcenPHdLSpUvVqFEjAapbt66+++47\nZ5tZLvuyzU7Z7ccq/uTtHuJ+X2sp3U5KlL1Uim8o5e23z/GLsUkbNSn9/3TnP+4o6jVce+21Do+m\n2ZAhhUVJj8VJ2W7mpikkPUP6+DvTb3rZ9dLXP0vZrt358uAArFbpfxtMMS98ytt3WMrKytL48eOL\nfnf9+vXT0aOu//g3N8XsjH2SdH6dGPcQ93cflP7vRvt1z9I/kRJaSZaT9jl+MbZpq97Q6/py3hcK\nDg42c8OHhGjBggUOab+Q0/nSDdFS14MVe8xzVSwWaclq6Zp/SA3CzcHXfYedbZUHR5OWLn30ndR+\nhNRhpHnjT0s3P9u1a5c6deokQD4+Ppo0aZLLhzlmWczOV1iUtKkS4czuIe45WdI/u0k/Tjv/b1hR\nUiZIJ3tJllT7tXEGf2mXpmiS/ozdoMGDBxf1Ju6++26dPOmYm4z0t5smJFL672n3d29EHZaemWaK\nfL87pC9+9KQ2qM7k50vL/5Dufd6MqhrzuNlrL7yOc3Jy9NprrxUNmrZs2VJ//vmnc42uANuzTDfM\njdFmLHtlcA9xl6SEo9KtjaVNSyr3TcvDapVOP1BQwckxkSz7FaUpmqRdlp2aNm1a0QVYv359ff31\n1w71xe/MkjofkK6LlhJctHzf+ZCTI/28zKwEVbendNtT0q+rzPc9uDdWqzmL+d9TpCYDpMtvMEs6\nxhYLdFm9erXatWt31mzxtDTXvtPnWaXXTpidra+q2NlyH3GXpF1rpJtDpejIyn/jsrDmS0ljpVMj\nzHBJBxCrY3pTk/WnNigqKkqDBg0quhgHDhyoyEg7fdcSyLaYaQsa7TP9fNWFk0nS+zOlvreZPth7\nnpMWrfQIvTthtUo790mvTJfaDpdaXG2Gxe45cO6+p06d0gMPPFD0O2rVqpVWrFjheKPPk73ZUo+D\n0tVHbJM2xL3EXZKWfGEOsKbZKdjZmmuKe9ItDpnkJEmnlKh39JaW63dZrBbNnDlTISEhAuTn56eJ\nEyc6NC5+XYY5821MtBRXDXrxZxITJ737jRR+u/kYf+cEacH/pEzHTjvwUAEsFjPn0FNvSpcOkS66\nyhwcXbe15B6t1WrVzJkzFRoaamZn9fXVf/7zH4fPKTlf8q3S24lmb/3jU7ZzjbqfuEvSR49Lz18j\n5dtJeayZpnvm9AN2KbJdEmlK0yearp80V3nKU2Jiou6///6i3kfr1q31+++/O8QWyRzMeS7eHKWv\n6uOhqxKbYPbo+98p1e4uDRsnfThL2n+ken5fdyA5VfplhfTgf6SG4VLHUdJL75tumLL+J3v27Dnr\nqbd///7au3ev4wyvJDuypF6HpP6HpQM2fpJ0T3HPz5NeuFZ6+377/QotqdLJPlLyQw4T+Bzl6DvN\n0mf6RKky/SKrVq1S27Ztiy7aa665Rtu3b3eIPZK0JVO6/KA04LC0x40jasojKVma86t093NS4/7m\nY/+4idKPS6WERGdbV33JzJKWrTNzCfW8WarVTRp8n/TmF+bgeHkcP35cDz74oLy8vAQoODhYX331\nlUPHqypDcr40Ps7sPH2WZJ+0IO4p7pKUmSb9s7v09Yu2ORMlYUmRTvaVkh90mMBbZFGEVmiq3lC0\noiVJ2dnZmjJliurUqSNAhmHo7rvvVnR0tENsyreaOSzqR5q9+TQ3jYuvKFartCvKHKQb+qA5INt6\nqHT/i9JX8zw9+6pwMklaGGFOLBp4t1TzcnMs5MX3pIg/Kz5PIS0tTRMnTlTNmjUFyNvbW+PGjdOJ\nE66dZc5qlb5Nlhrvk+6PlU7a0e1Zmri7R5m95BPw7yvg+n/ByEfsY4A1DU6PAO8wqPslGI4pcx7J\nXn7hZ4ZwLV25HDALck+aNInp06eTl5dHQEAATzzxBM8++yxBQUF2t+l4Hkw4AREZMLkB3F4XvFy0\nILctsVjgr/2wdqu5rNli1n/tcxl06wDd2sPl7aFhiLMtdS2yc2DPQfhzJ6zfbi4nkqBnJ/Pc9ekC\n4d2gds2KHzMvL48vv/ySl19+mYSEBABGjx7N5MmTadu2rZ2+iW3YnQ2PxkOqFT5qBL1r2Le90gpk\nu4e4A8QdgifD4ZEPIXyMfYxQJiSNBq8gCPoWjLLKnNiOk5xgNrNoRSuuYSjeeANw6NAhXnjhBb7/\n/nsAgoODeemll3jooYcICAiwu13rM+GJePA24L1G0DPQ7k26FBIcPQ4bdsDWPeayZQ/UDDRFvlt7\nsy5s2xbQ8iLwc8zl4jQkiE+EHZGwM8pc79gHB2PM79+joynmvbtA+0vB27sybYj58+fz3HPPsW/f\nPgB69+7N1KlTCQ8Pt/E3si0n82HiSZibCi+HwkP1zN+OvXF/cQfYvxVevBae/Q66DrKPIcqG0zcD\nFgj6AbzOo7tRBbLI4kd+IJdcbmIsdahT9NmmTZt4+umnWbVqFQCNGzfmySefZNy4cdSqVcuudlkF\nM1Pg+RNwZU14LbSc0l7VHAmOxMKW3eay+yDsPQgx8XBxE2gdBm3CTLFr0QyaN4Lmjc+v1+pMLBZT\nwA/GwMFoOBBdsF3w2jCgS1vo0ubvpX1L8K/iNWGxWJg7dy6TJ09m586dALRs2ZIpU6YwZswYDMN1\nHx0zrPDuKXgnyXzK/U8I1HfMgz9QXcQdYOcqmHQTTPwF2vexjzHKg5QHID8KgheDV7B92imGFSur\nWclG/uQ6rqcNfz9+SmLx4sW89NJLbN++HTB78o8//jiPPfYYwcH2tTHdCtMS4YPTcEddeC4EGjnw\nAnZ1cnJN8Ys6AvuOwP6jZq8/Jt5c/HwLhL4RNG0IofUgpHAJ+nu7Ti3zycDfzxTSqmK1QkoaJKeZ\nNWxPpxSsU00RP36iYDlprk8kQf26cOlFcGlzc2l50d+vQ+rZxq5CcnNzmTlzJlOmTOHAgQMANGnS\nhOeee45x48bh6+tru8ZsTJ7g89PwWiL0rwH/Fwqt/B1vR/URd4DNv8HUu2DSUmjZ1T4GSZA2AXIW\nQfBS8G5un3ZK4ChH+JG5tKMdV3MNvvx9gUvit99+Y9KkSaxbtw6AWrVq8fDDD/Ovf/2Lxo0b29W2\n+HyYkgjfJMP99eCZ+hDqEfkykSApBWLiIDrOFNHEZEg8XbAUbJ9MgtQMyMgEi9UU+cKlRiD4eJvC\n6uVljoEUbkvmzSUnF7IL1znmOjMbatWAenUKlroQVNvcbhxqLk0aQJOCdaMQcISeZmZm8sUXXzB1\n6lSOHTsGwCWXXMKzzz7LXXfdhb+/E1SyglgE36fCxBNwiZ85LtXNiS7L6iXuAGvnwfRHYNLvcEln\n+xmW/hZkvg/1loBve/u1U4wssviFn0niFDdxC6GEnvW5JNasWcPrr7/O0qVLAfD39+e+++5j/Pjx\ntG7d2q72HcuD1xNhTqrpW3yyPgRXwsfqoWTy8kxhzsgyxT4z2xR8q9UUc6vVdJkV/mT8/SDAr2Dt\nb679/aBGAPi40M03MTGRzz77jHfffZeTJ08C0KFDB55//nluvvlmfFzJ2GLkC75PMXvqId7wSigM\nsq9XtEKUJu5OD4EsXKhMsY5Vc6RbGtkvD3whmd9K8Q2kbMdObbbKqk36U5P1mjZpo6wqOS5v06ZN\nGjNmTFGMPKCrr75aP//8s/Ly7Dv19EiO9ECsGT45MUFKrGYzXT1UHavVqg0bNuiuu+4qyqsEqGfP\nnvrll19ksbh2zG2uVZpxWmq9Xwo/JC1Pc60QWdw2zr08Ir6TbmkoRdm5HmJ2hJkPPv0j+7ZTAglK\n0HR9oJmaoRSVXgF79+7duv/++xUYGFj0A2revLlee+01xcfH29XGAznSfbFS0F7p4ePunVrYg23I\nyMjQF198ocsvv7zoejQMQ8OHD9eyZctcfgJSukX64JRZl/iqw9KKdNcS9UKqr7hL0tp50tgG0p71\nlT9GRcg7IJ1oJyU/4rCEY0VNK0/LtUyT9Zq2aFOpvXhJSkpK0jvvvKNWrVoV/ah8fX11yy23aPXq\n1Xb9UcXlSS8kmPkzRkdLazNc8wfhwX7s27dP48ePV1BQUNH1V79+fU2YMEGHDh1ytnnlEp1rJtYr\nvIY3ZDjborKp3uIuSX8uNjNJ7lxVteOUhyVZOjXMzEljcfx89Tgd10f6QF/rvzqtpDL3tVgsWrZs\nmUaPHl00bRtQu3btNGnSJB0+fNhudqZbpA9PSZdGmTk15iSbj7ceqidJSUn67LPPNGDAgLPcg717\n99Y333zj8km9JGl9hjQ2Rqq310wZcNCFs4nmKU//03It17ILQNwlaety6eYQaYudE29Z86WUp6SE\nS6Xc3fZtqwTyla9VWqnJek1/ar0sKt9nGR0drRdffFENGzY868cXHh6ujz/+WImJ9rlR5VuleSlm\nwqTG+0y//DHHPvR4sBNZWVmaO3euRo8eLT8/v6JrKjAwUA888IC2bLGzq9QG5Fil75LNDkiLKOnd\nRCnFtQs36aiO6n29q2/1jZKVfIGIu/R3Lvg1P9rmeGWR8bUUHyJl/mD/tkrghBL0qT7W5/pU8aqY\nTz03N1eLFi3SLbfccpZv3tfXVyNHjtScOXOUmVmJWl8VYFeW9Mhxs2c0OlpanGqKvwf3IT8/XytW\nrNB9992nunXrFl0/Xl5eGjx4sL766iulpLh+kYC/sqR/x0kNIqUrD5tF5F39WsxUphZovt7Q69ql\nnUWu2dLE3X1DIcviwDaYOAJumgCjH7fNMUsjdzMk3wz+w6HONDAcG59rxcpmNvI/VtCFy7iSQQRQ\nsdQEaWlpzJ8/n1mzZrFs2TKsVisAtWvXZsSIEYwaNYprr73W5vls0ixmnPBnpyEhH+4JgjvrOmcC\niIfyycnJYeXKlSxcuJD58+cTGxtb9Nnll1/O7bffzi233EKTJk2caGX5pBRcd/89DccKrrt7g6Cl\ni8+4FmIH2/md32hHewYzhED+DqyvfnHu5RF/BF4aCj2Hw/1vmrM97IU1GZLvA2sMBM0Bn0vs11Yp\nZJDBcn5nH5FczTV04TK8qPh3TkhIYM6cOcyaNYuNGzcWve/j40P//v0ZOXIkI0eO5NJLL7Wp3duy\nYEYKfJcCLfxMkR9bB0JcN9z5giAxMZHFixezcOFCli5dSnp6etFnLVq04Pbbb+f22293+SReeYJl\n6TA7FRalweCacF8QXFPLMXlfqkocx/mVxeSSy0hG0YxzJ1NeeOIOkJYEL18HIU3hyRngZ8euoWRO\ndkqfBHU/hYDr7ddWGcRyjEUsxMBgOCNoSrPzPsbBgwdZsGABCxYsYM2aNVgslqLP2rdvXyT0vXv3\nxrsy2aFKIF/we7qZx+bXdBhYA+4MguG1INCO92UPJpKIjIxk4cKFLFiwgPXr1xc9yQF07tyZkSNH\nMmrUKHr06OHSuV6sgvVZMCvFTOLV2g9uqws313Gf2dQZZLCCZexlD1cxmG50L7Wz5hbinpOejl9N\nG2dYys2GN++AlJPwn5+htp3zxORuLHDTjIY6bzjcTQOmq2Y721jO77ShLVcxmNrUrtSxTp8+zZIl\nS1i4cCFLliwhJSWl6LOgoCD69+/PwIEDGThwIJ07d7aJ2Kda4Kc0+DYZtmTD0Fowpo65ruURepsg\niUOHDrFy5cqipTANAICvry9XXnklo0aNYsSIEVx88cVOtLZ8rILN2TAv1XS91PSC2+vArXXNJ0J3\nIZ98NvInq1lJZy7jSq46ywVTEm4h7l/27cttixcTYOuc5VYrfPkMbFgAryyCZvadmo81CZIfAMsh\nCJoJvp3s214pZJHFKiLYxlZ60Itw+lXYH18SeXl5rFmzhoULF7Jo0aKiRE+FnCn2V155JZ07d8ar\niu6wE/nwcxr8nAp/ZMGAGjC6Noyq7T69MFdAEocPHz5LzGNiYs7aJyQkhGHDhjFy5EiGDBlCnTp1\nSjmaa5BphRUZsDANFqab6S9G1TIFvZO/bROc2RshdvMXy/idEEK4hqE0oEGF/tYtxH3JE09wZOVK\n7li6lFoNG9q+kSVfwIwX4Jlv4fKrbX/8M5Eg62tIewZqPgM1/w2Gc5KvJJNMBCuIYh/h9Kcnvc5K\nRlZZjh49yqpVq1i5ciUREREcOXLkrM/r1atHeHg4PXr0oFu3bnTv3p0GDSp2wZZEigUWp8P8NFia\nDm39zN780FrQPdA9fKiOIi0tjW3btrF582Y2b97M2rVrzxHz+vXrM2DAgKInrw4dOlT5ZmxvYvLM\n//3CNIjIhG4B5o1+ZG3XHxgtCSEOcoAVLMOKlSEM5VLOb1zLLcTdarWy6tVX2TVrFncuW0aQPR4F\nd62G18fCTc/A9ePtf3vPPwIp94AsEDTDKYOthZwggRUs4zjHuZKr6ELXosIgtuDIkSOsWrWKiIgI\nIiIiiI6OPmef5s2b071796KlW7du1K9f/7zbyhWszYQl6eYSnw9DappCP6QWNLyAevWZmZls3769\nSMg3b95MZGQkxX/bwcHBZ4l5x44dXV7MM6ywKgN+zzDHZE5YzEHRkbXN/7U7J6s7yhGWs4x00hnE\nYNrT4byCIAqxubgbhnET8DLQFughaWsp+10LvAt4A19IeqOU/YoGVDe89x4b3n6bO5YuJcQeo/EJ\nR+HV0RDWCR7/FPztnK9TVsh4FzImQ+3XIfABpz4zRhPNMpaSQQZXchUd6Fipi6o8Dh8+zPr169m8\neTNbtmxhy5YtZGRknLNfWFgYnTp1om3btkVLmzZtzkv0Y/LgtwKhj8iAxj5mcZEra5qDs9Uh+iYj\nI4OoqCgiIyOLlj179rBnz56zBj/BjHLq3Llz0Q20V69edOrUyeXFPMcKm7JhdQYszzC3uweYN+wh\nNaFrgPuXfIzjOMtZxglOFHSyLqtSJ8se4t4WsAKfAk+WJO6GYXgD+4DBQCywCbhV0t4S9j0rWmb7\n11+z4rnnGDt/Ps169aqUjWWSnQnv3AfHD8ALP0KjMNu3UZy83ZB8F3iFQN3PwMd5g1RCHOAAK/kf\nWWTRj/50potNe/LFsVgsREVFndXD3LZtG1lZWSXuHxIScpbYt2nThosuuohmzZoRHBxcasSGRbA9\n2xT5iEyzh9/cF/rVgD6B0CsQWvm5pkikpaVx7NgxYmJi2L9/P/v27SsS8uJulUK8vb3p2LFjkZB3\n796dTp06OaQUY1U5lW+OpazNhHWZ5v+trb/5vxpcEwbUrD6D6LEcYzWrOEYM/RlAN3rgQ9V7HXZz\nyxiGEUHp4t4HmCjp2oLXzwJImlLCvueEQkYtWsQv997LyC++oO1111XJzhKR4Od34Ycp8OTX0GOo\n7ds4p808yJgK6W9Dreeh5uMOK8ZdojmIwxxiFSs5TRLh9KMr3Wzik68I+fn57Nu3j717957VI923\nb99ZsdXFCQgIoFmzZjRr1ozmzZsXbTdr1ozGjRsTHBxMUFAQQUFByMubHdmwKhP+zIKNWZBsgR6B\nZl3YXgVre7lyJJGamsrp06dJTk4mPj6eY8eOlbicGY1UHF9fX1q1anXOE06nTp0IDHT9ArepFtiW\nbUa1bM4y1yfyzfN/RQ0ID4ReNaqPmIP5+zrEQdawmlMk0pdwutEdP2w3QOAscb8RuEbSPwpe3wH0\nkvRYCfuWGOceu2kT3193HVdMmEDvJ56okq2l8tcamHwLXPsA3PafylX2PV/yoyDlYXMCVNBn4NvN\n/m2WQwzRrGIlcRynN33pTo9yw7DshSSOHz9eJPSRkZHs37+fmJiYckWwOHXq1KFevXpFS1BQEAF1\n65FRow4nvfyIx5c4/PDx86NJoC/NA/24qKYfLQJ9aV7DD18vg7y8PHJzc8nNzS11OyMjg9OnTxeJ\n+Jnbxd0mpREYGEizZs1o2rQpLVu2pE2bNkVCHhYW5tLFLAqRIDoP/soxl53ZZkjrsTzoHGAOfncv\nWLfxq54D4Vas7GUPa1hFHnmE059OdLZJT704lRJ3wzCWAY1K+Oh5SQsL9ilL3G8Arq2KuAMkHznC\nrGHDuOTqq7nm7bfxsof4JsXDG7eZV+aE2VDfvuXqgIKImplmRE3ALVD7/8CrcvHotiSeONayhv1E\ncRld6U1f6lHP2WadRVpaGrGxsUU93kLRP3bsGHFxcUWimpKScs7AojOoVatW0c0lNDT0nKeNwtf1\n6tVz6QlCZ5IrOJwLB3Jhfy7syflb0Gt7QUd/MySxY4AZ1dLOH3zc46tVmjzy2MF21rGGQGrQj/60\noa1dxrQKcVbPvTfw8hlumecAa0mDqoZhaOLEiUWvC0f0C8lOTuaHG27At2ZNxsyahX9tO4igxQLf\nvQaLPzHdNN2vsX0bJWFNhNSnIWcF1H3PnADlAj/wFJLZwAa2splLaUlv+tCcizBwvm0VxWKxFLlE\nii/p6ekl9sLPfC8rN4/kfCuZ3n6ke/uR6uVLipcfyV6+BPj5ERzoR7C/L/UD/GhQM5CL6tfjkpB6\ntA6pR5P6fz8puHKh59LItsLxfLPHfSwfYvPgSJ4p5AdyITYfmvuYIYgt/aB9gZh3CHDvKJbKkEIy\nm9jEFjbRlGZcQT/CCLPLb6VwnkIhr7zyil3F/SlJW0r4zAdzQHUQcBzYSAUHVEvCkpvL4kceIXbj\nRm5dsICgsLAq2V4qOyJg2t0QfgPcOxn8HDQwlbMSUh8FryZQ5x3w7eiYdsshhxy2soU/WU8AgfSk\nFx3pZFO/obthlRmhcygPjuaZbogz1zF5Zi+1obfpyy9avM3JV0HeEORVbO0NNQzb39clyBSkWU2/\nd5rVXE5Z4GQ+JFrgpAUS8831iXxTuFOt0MQHmvpAM19o5gMX+ZpC3soPLvYDP/e5z9scc7zqMBvZ\nwGEO0ZnL6EUvQorVO7Y39oiWuR54HwgBUoBtkoYahtEE+FzS8IL9hvJ3KOSXkiaXcrwK5ZaRxJ/v\nv8+6KVO48YcfuLhfv0rZXy5pSfDegxC733TThHWwTzvFUR5kfgrpr0LAjVD7VTO6xgWwYmU/UWxi\nIzFE05kudKcnDbHDhDM3RzLFMSG/YLGYsfgJBQKaYoEUqzmwm2yB5ILtbIG/AYEGBHiZ60AvCDDA\nCzAwo3wM/l7AdJHkFazPXDKtkG41j1nbC+p4m+vaXlDfG0K9zTDRUG+z6HPhdjNfc+2KEUXOJoss\ndrCdTWzEAHrSmy5chj/OSWvqFpOYzseWA0uXMv+uuxgwcSLdH37YPn5KCZb+F7561hxoHfmofbNL\nnok1CdJegezZUPN5qPkoGK7TU04mmS1sZiubCaIePehJBzo6LMqmumKVKfBZ1oK1TPdIlszPChOo\nWwvWhT8ZP+PcxbfgxlDbq/r7uu2NEEc4zBY2E8U+WtGa7vQgjBZOd1NWO3EHSDpwgDnXX0+THj0Y\n/tFH+Ngrrjd2P0y9CwJqwr//Cw0usk87JZG3F9L+DfmHoM5bZt54F/DHF2LBQhT72MRGjhNLRzrR\nlctpQlOnX/QePFSVNNLYzja2shlvvOlGD7pwGTWo4WzTiqiW4g6Qm57OL/fdx+lDh7hp7lzqtWhh\nB+sASz7MfRN+fgfued0Mm3SkyGYvgbSnwAiG2pPAv7/j2q4gyZxmO9vZzla88KIzl9GZLgRj50yc\nHjzYkGyy2csedrGTY8TQng50ozvNaO6SHZZqK+4AERERBO7YwdrJkxn15Ze0HjHCxtadwZG/4O37\noEYdGP85NLLTzaQkZIGsWZD+Mvi0NkW+EvHxK1euPCsSydYIcYwYdrKDv9hFMPXpQhfa0aHSqYed\nib3PV3XDHc9XHnlEsY9d7OQgB2hBCzrRhTa0tXvgQKXOlzUR0t8Er3oYtZ8vUdyrxVywVatW0Xv8\neMb+/DOLH3mEFc8/jzU/3z6NhXWEd/6AbkPg8R7wywdmSmFHYHhDjbsgNBL8r4OkUXD6Bsjbc16H\nOTOMyh4YGDTnIoYzkqeYQH8GEE00H/Au/+UL/mQDaaTa1QZbYu/zVd1wl/OVRx6R7GUePzKVKWzk\nT1rRin/xFLdxJ53o7JCIsPM6X9bTkPYinGgDSofAu0rd1fWnu50Hzfv25cEtW5h3++3MuOoqbpg9\nmzrNzr8SUbl4+5hZJXtfB+/cDyu/gyc+M4XfERh+UPNhqHE3ZEyHpIHgNwRqvwg+rlX2zBtv2tCW\nNrQljzwOcoDd/MUKltGQRnSgI+1oT13qOttUDxcAOeQQxT72socD7KcRjWlfUJe0Di6cv96aWpB8\n8H0IGA0hW8AnrMw/qVbiDlAzNJQ7fvuNtVOmMHvECMZt3YphrwiX5m1g2mpY8jlMuAre2+iYBGSF\nGDWg1tNQ40HI+BBO9Ye630DAtY6z4TzwxZe2tKMt7cgnnwPsZzd/EcEKLqUlN3OLs030UI3ZyQ4W\n8gvNuYj2dGAYI6hFLWebVT7KgZMdwX8ghGwAn5YV+jOX8rk72wYPHjx4cEdcekDVgwepQ/+VAAAD\nSElEQVQPHjzYjmoxoOrBgwcPHs7GI+4ePHjwUA1xS3E3DOMmwzB2G4ZhMQzj8jL2u9YwjEjDMPYb\nhjHBkTa6EoZhBBuGscwwjCjDMH43DCOolP2OGIax0zCMbYZhbHS0nc6mIteLYRjvF3y+wzCMro62\n0ZUo73wZhjHQMIyUgutpm2EYLzrDTlfAMIz/GoaRYBjGrjL2se21JcntFsy6ra2BCODyUvbxBg4A\nYYAvsB1o52zbnXS+3gSeKdieAEwpZb/DQLCz7XXSOSr3egGGAb8WbPcCNjjbbhc/XwOBBc621RUW\noB/QFdhVyuc2v7bcsucuKVJSVDm79QQOSDoiKQ/4HrBDrT63YBQwo2B7BjC6jH1db361Y6jI9VJ0\nHiX9CQQZhnGhpsSs6O/rQr2ezkLSGuB0GbvY/NpyS3GvIE2BMysKHyt470KkoaSEgu0EKDVHr4Dl\nhmFsNgzjH44xzWWoyPVS0j52mCXnFlTkfAnoW+Bm+NUwjPYOs879sPm15bKTmCpS4q8cLqgYzzLO\n1wtnvpCkMuYUXCEpzjCMUGCZYRiRBT2OC4GKXi/Fe6IX1HV2BhX53luB5pIyC+o6zMd0p3ooGZte\nWy4r7pKuruIhYoHmZ7xujnk3rJaUdb4KBnIaSYo3DKMxcKKUY8QVrE8ahvEz5qP3hSLuFbleiu/T\nrOC9C5Fyz5ektDO2lxiG8ZFhGMGSkhxkozth82urOrhlSvPpbQZaGYYRZhiGHzAWWOA4s1yKBcDd\nBdt3Y/agzsIwjBqGYdQu2K4JDAFKHdmvhlTkelkA3AVF9YGTz3B3XWiUe74Mw2hoFFTRMQyjJ+ak\nSY+wl4zNry2X7bmXRbESf4sNwzinxJ+kfMMw/gks5e8Sf+fUbr1AmAL8YBjG/cAR4GaAYiURGwHz\nCn6LPsAsSb87x1zHU9r1YhjGuILPP5X0q2EYwwzDOABkAPc60WSnUpHzBdwIPGwYRj6QCRdu8iDD\nML4DBgAhhmHEABMxo4zsdm150g948ODBQzWkOrhlPHjw4MFDMTzi7sGDBw/VEI+4e/DgwUM1xCPu\nHjx48FAN8Yi7Bw8ePFRDPOLuwYMHD9UQj7h78ODBQzXEI+4ePHjwUA35f85Yg5pkvH3wAAAAAElF\nTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fa0e3bae898>"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.isfinite?"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 2,
     "source": [
      "Reproducing the example exactly"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sympy\n",
      "\n",
      "x1 = sympy.Symbol('x1', real=True)\n",
      "x2 = sympy.Symbol('x2', real=True)\n",
      "\n",
      "f = 2*(x1**2 + x2**2 -1) -x1\n",
      "h = x1**2 + x2**2 -1\n",
      "h2 = h**2"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = sympy.Matrix(((sympy.diff(f, x1),),(sympy.diff(f, x2),)))\n",
      "sympy.pprint(df)\n",
      "dh = sympy.Matrix(((sympy.diff(h, x1),),(sympy.diff(h, x2),)))\n",
      "sympy.pprint(dh)\n",
      "dh2 = sympy.Matrix(((sympy.diff(h2, x1),),(sympy.diff(h2, x2),)))\n",
      "sympy.pprint(dh2)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u23a14\u22c5x\u2081 - 1\u23a4\n",
        "\u23a2        \u23a5\n",
        "\u23a3  4\u22c5x\u2082  \u23a6\n",
        "\u23a12\u22c5x\u2081\u23a4\n",
        "\u23a2    \u23a5\n",
        "\u23a32\u22c5x\u2082\u23a6\n",
        "\u23a1     \u239b  2     2    \u239e\u23a4\n",
        "\u23a24\u22c5x\u2081\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0\u23a5\n",
        "\u23a2                    \u23a5\n",
        "\u23a2     \u239b  2     2    \u239e\u23a5\n",
        "\u23a34\u22c5x\u2082\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0\u23a6\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ddf = sympy.Matrix([[sympy.diff(df[0], x1), sympy.diff(df[0], x2)],[sympy.diff(df[1], x1), sympy.diff(df[1], x2)]])\n",
      "sympy.pprint(ddf)\n",
      "ddh = sympy.Matrix([[sympy.diff(dh[0], x1), sympy.diff(dh[0], x2)],[sympy.diff(dh[1], x1), sympy.diff(dh[1], x2)]])\n",
      "sympy.pprint(ddh)\n",
      "ddh2 = sympy.Matrix([[sympy.diff(dh2[0], x1), sympy.diff(dh2[0], x2)],[sympy.diff(dh2[1], x1), sympy.diff(dh2[1], x2)]])\n",
      "sympy.pprint(ddh2)\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u23a14  0\u23a4\n",
        "\u23a2    \u23a5\n",
        "\u23a30  4\u23a6\n",
        "\u23a12  0\u23a4\n",
        "\u23a2    \u23a5\n",
        "\u23a30  2\u23a6\n",
        "\u23a1     2       2                        \u23a4\n",
        "\u23a212\u22c5x\u2081  + 4\u22c5x\u2082  - 4       8\u22c5x\u2081\u22c5x\u2082      \u23a5\n",
        "\u23a2                                      \u23a5\n",
        "\u23a2                        2        2    \u23a5\n",
        "\u23a3     8\u22c5x\u2081\u22c5x\u2082        4\u22c5x\u2081  + 12\u22c5x\u2082  - 4\u23a6\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lam, c = sympy.Symbol('\u03bb', real=True), sympy.Symbol('c', real=True)\n",
      "\n",
      "L = f + lam*h + c/2*h2\n",
      "dL = sympy.Matrix([[sympy.diff(L, x1)], [sympy.diff(L, x2)]])\n",
      "sympy.pprint(dL)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u23a1       \u239b  2     2    \u239e                    \u23a4\n",
        "\u23a22\u22c5c\u22c5x\u2081\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0 + 2\u22c5x\u2081\u22c5\u03bb + 4\u22c5x\u2081 - 1\u23a5\n",
        "\u23a2                                          \u23a5\n",
        "\u23a2         \u239b  2     2    \u239e                  \u23a5\n",
        "\u23a3  2\u22c5c\u22c5x\u2082\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0 + 2\u22c5x\u2082\u22c5\u03bb + 4\u22c5x\u2082  \u23a6\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ddL = sympy.Matrix([[sympy.diff(dL[0], x1), sympy.diff(dL[0], x2)], [sympy.diff(dL[1], x1), sympy.diff(dL[1], x2)]])\n",
      "sympy.pprint(ddL)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u23a1      2       \u239b  2     2    \u239e                                                \n",
        "\u23a24\u22c5c\u22c5x\u2081  + 2\u22c5c\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0 + 2\u22c5\u03bb + 4                 4\u22c5c\u22c5x\u2081\u22c5x\u2082            \n",
        "\u23a2                                                                             \n",
        "\u23a2                                               2       \u239b  2     2    \u239e       \n",
        "\u23a3               4\u22c5c\u22c5x\u2081\u22c5x\u2082                 4\u22c5c\u22c5x\u2082  + 2\u22c5c\u22c5\u239dx\u2081  + x\u2082  - 1\u23a0 + 2\u22c5\u03bb \n",
        "\n",
        "   \u23a4\n",
        "   \u23a5\n",
        "   \u23a5\n",
        "   \u23a5\n",
        "+ 4\u23a6\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}